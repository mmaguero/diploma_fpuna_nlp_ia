{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmaguero/diploma_fpuna_nlp_ia/blob/master/2025/guarani_wiki_question_answering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE6PyrHxtEw0",
        "outputId": "b01d771a-ac1c-436a-a794-10fd1eba2be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "# Transformers installation\n",
        "! pip install transformers datasets evaluate accelerate\n",
        "# To install from source instead of the last release, comment the command above and uncomment the following one.\n",
        "# ! pip install git+https://github.com/huggingface/transformers.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCWa3GqetEw3"
      },
      "source": [
        "# Question answering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "cellView": "form",
        "hide_input": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "7gbYfcCLtEw4",
        "outputId": "c4231597-88a7-424b-c3c9-7b7228c1509f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/IPython/core/display.py:724: UserWarning: Consider using IPython.display.IFrame instead\n",
            "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/ajPx5LwJD-I?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "#@title\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/ajPx5LwJD-I?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO6vRtTKtEw5"
      },
      "source": [
        "Question answering tasks return an answer given a question. If you've ever asked a virtual assistant like Alexa, Siri or Google what the weather is, then you've used a question answering model before. There are two common types of question answering tasks:\n",
        "\n",
        "- Extractive: extract the answer from the given context.\n",
        "- Abstractive: generate an answer from the context that correctly answers the question.\n",
        "\n",
        "This guide will show you how to:\n",
        "\n",
        "1. Finetune [DistilBERT](https://huggingface.co/distilbert/distilbert-base-uncased) on the [SQuAD](https://huggingface.co/datasets/squad) dataset for extractive question answering.\n",
        "2. Use your finetuned model for inference.\n",
        "\n",
        "<Tip>\n",
        "\n",
        "To see all architectures and checkpoints compatible with this task, we recommend checking the [task-page](https://huggingface.co/tasks/question-answering)\n",
        "\n",
        "</Tip>\n",
        "\n",
        "Before you begin, make sure you have all the necessary libraries installed:\n",
        "\n",
        "```bash\n",
        "pip install transformers datasets evaluate\n",
        "```\n",
        "\n",
        "We encourage you to login to your Hugging Face account so you can upload and share your model with the community. When prompted, enter your token to login:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61,
          "referenced_widgets": [
            "79923602ad684364b96b4f04f6df9512",
            "d3d9f44db6db413a97cc3a8948ffa5dc",
            "4d63bad454ca439389431cf44acf546f",
            "7d1b3193f2bc4cbbbbb6aa08aa096600",
            "585a31b5282d4e129222f30b5a3b9bdd",
            "121926a260e74f128a908588172a5bfd",
            "396f9d07c84244799acb36ea07277a37",
            "44f15dc0109448b2919faba466feca86",
            "86141c3231ed4da5bc3e88e639e148d2",
            "6a3925dba8344196be1eb6a2db9c86ec",
            "0b8baa4903de4dc0843d85e2601ade18",
            "a9d02c340b8c4716b3fe46910abbb4c3",
            "6fb345693fdc49fb9d5b4e24332a651f",
            "d0952fd951d04694b8bb28c44beb3ff7",
            "e52863f611a64905a54abcef0f5828ac",
            "84baa25590a64e58bea7c18f20fbe6c3",
            "bf52da850aa94074886ba9dbedfedcb8",
            "309a9f6371f747baa3235a60e5877161",
            "99e3aa9bf08b4fa5913217d1bd879bb2",
            "031a99086d8b4a27b3b5134a9eb4f05f",
            "0051708a588b448991e4334bb96bd048",
            "56637554015d4e9c95e3e9f72ab3f877",
            "4de35a30469c422aacee901f434891f3",
            "ce5a3c598b8c425daefb5c1d6bd5c13f",
            "e12559a505884b5d90469cca9a02e303",
            "509a135a07c240ab8a39875fcc76d0cb",
            "8a944d227d584af8b81ffa286bd8ee21",
            "9c8b6ea9171848faa10b0efe7f98c41b",
            "76c2589bc33040a0a5a85ea483b9cd94",
            "12c03d01af92403c910e2a69b61e9c86",
            "865a289a4abb41ac99466e8dd55c46e6",
            "3edaeb0bad2642eb837e9460266b25a0"
          ]
        },
        "id": "sbEYWEybtEw6",
        "outputId": "2e59acc5-ad40-424a-8b7c-85fe398e381e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79923602ad684364b96b4f04f6df9512"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VXV24O7tEw6"
      },
      "source": [
        "## Load SQuAD dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI0eDeNDtEw7"
      },
      "source": [
        "Start by loading a smaller subset of the SQuAD dataset from the ðŸ¤— Datasets library. This'll give you a chance to experiment and make sure everything works before spending more time training on the full dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "nkdJ8zP_tEw7"
      },
      "outputs": [],
      "source": [
        "#from datasets import load_dataset\n",
        "\n",
        "#squad = load_dataset(\"squad\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpdpITEtEw8"
      },
      "source": [
        "Split the dataset's `train` split into a train and test set with the [train_test_split](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.train_test_split) method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "W7LFeHN6tEw8"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# 1. Reload the original squad dataset\n",
        "squad = load_dataset(\"alexandrainst/multi-wiki-qa\", \"gn\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-jUG9fjtEw8"
      },
      "source": [
        "Then take a look at an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-i5t-TqtEw8",
        "outputId": "a36b7e02-63f3-475f-fd95-c1eb35cbea64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(912,\n",
              " {'id': 'https://gn.wikipedia.org/wiki/Ypa%E2%80%99%C5%A9%20Umbu',\n",
              "  'title': 'Ypaâ€™Å© Umbu',\n",
              "  'context': \"Umbu peteÄ© ypaâ€™Å© michÄ©va oÄ©va tetÃ£vore Ã‘e'áº½mbukÃºpe, opyta 12 km ko tetÃ£â€™i tavusÃºgui. Ojekuaa Cuenca lechera Ã‘e'áº½mbuku ramo.\\n\\nTÃ¡va \\n\\nKo tÃ¡vape oiko 320 yvypÃ³ra, haâ€™ekuÃ©ra hory ha ojokuaapa, upÃ©vare ojoayhu hikuÃ¡i.\\nUmbÃºgui ou Pilarâ€“pe 3000lts kamby. ko ypaâ€™Å©me oÃ±eÃ±angareko gueteri umi tavaâ€™i ymagua rehe. \\n\\nHeÃ±Ã³i ary 1860â€“pe, karai Carlos Antonio LÃ³pez ohenda umi pyaenda ypy oÃ±emopuâ€™Ã£ hagua TupÃ£o. Ojapoma 150 ary  heÃ±Ã³i hague ha koâ€™Ã¡gaite peve oÃ±emombaâ€™e ha ojeguerohory avakuÃ©ra mborayhu.\\n\\nTupÃ£o UmbÃº  megua haâ€™e mbaâ€™e ojeguerohory ha oÃ±embotuichavÃ©va ko tÃ¡vape, ary 1862-pe ojejapovaâ€™ekue ha koâ€™Ã¡ga meve oguerekÃ³iti estilo colonial siglo XIX pegua, ogyke iÃ±anambusÃºva, Ã³gahoja karandaâ€™y, takuarilla ha Ã±ayâ€™Å© kaiguÃ©gui. HenondetÃ©pe oÄ© peteÄ© kurusu yvyrÃ¡gui ojejapÃ³va.\\n\\nIta marangatu mbytetÃ©pe oguapy San Anastasio. Ojeâ€™e San Anastasio haâ€™eha ypaâ€™Å© UmbÃº pytyvohÃ¡ra marangatu. Mcal. Francisco Solano LÃ³pez ojerure rupi Ã±orairÃµ guasu aja, osáº½ porÃ£mba hagua.\\n\\nAry 1866â€“pe karai Mcal. Francisco Solano LÃ³pez heâ€™i San Anastasioâ€“pe: osáº½ porÃ£rÃµ Ã±orairÃµ Estero Bellacoâ€“pe, upeicharÃµ ojapota upÃ©pe TupÃ£o, ha upeichaite oiko upÃ©vare ko tupÃ£o raáº½vete ojejapo vaâ€™ekue Ã±orairÃµ guasu opa rire.\\n\\nTupÃ£o\\n\\nAry 1970â€“pe, oÃ±emyatyrÃµ Ã±epyrÅ© rakaâ€™e ko TupÃ£o. YvyporakuÃ©ra upÃ©pegua omoÄ© jey pe itapu renda oÄ© haguÃ©pe voi. AvakuÃ©ra oÃ±angareko koâ€™Ã¡gÌƒaite peve ypaâ€™Å© UmbÃº rehe.\\n\\nMuseo HistÃ³rico de Isla UmbÃº\\n\\nOÃ±emyatyrÃµ ha oÃ±eguaháº½ jey upÃ©pe ojapo irundy ary. OÃ±emboâ€™e avakuÃ©ra pukoe rupive iporÃ£ha oÃ±eÃ±angareko umi mbaâ€™e ymaguare rehe, oguerekÃ³va ko ypaâ€™Å©.. Heta ava ogueraha museo-pe umi mbaâ€™e ymaguarÃ©va oguerekÃ³va hÃ³gape ikatu haguÃ¡icha ombojeguave ko tenda.\\n\\nMuseo ryepÃ½pe oÄ© peteÄ© yvyra ygue paâ€™Å© oipurÃºva avakuÃ©ra ygua ramo ha oÃ±eÃ±ongatu hagua kaâ€™avo raâ€™á»¹i ha umi ao oipurÃºva paâ€™ikuÃ©ra. Heta mbaâ€™e ymÃ¡guare oguereko ko museo.\\n\\nReferencias\\n\\nGeografÃ­a Ilustrada del Paraguay, Distribuidora Arami SRL; 2007. ISBN 99925-68-04-6\\nGeografÃ­a del Paraguay, Primera EdiciÃ³n 1999, Editorial Hispana Paraguay SRL\\n\\nEnlaces externos\\n\\n Secretaria Nacional de Turismo \\n\\nParaguÃ¡i tava\",\n",
              "  'question': 'Mbaâ€™e mbaâ€™Ã©pa ikatu jajuhu Museo HistÃ³rico de Isla UmbÃºpe?',\n",
              "  'answers': {'answer_start': [1655], 'text': ['peteÄ© yvyra ygue paâ€™Å©']}})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "import random\n",
        "rnd = random.randint(0, len(squad[\"train\"]))\n",
        "rnd, squad[\"train\"][rnd]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding a true ID, the existing ones is the URL and can be duplicated..."
      ],
      "metadata": {
        "id": "l-Cw-4IynnIy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efe6df69"
      },
      "source": [
        "import hashlib\n",
        "\n",
        "def generate_md5(input_string):\n",
        "    \"\"\"Generates an MD5 hash for the given input string.\"\"\"\n",
        "    # Encode the input string to bytes\n",
        "    encoded_string = input_string.encode('utf-8')\n",
        "\n",
        "    # Compute the MD5 hash\n",
        "    md5_hash = hashlib.md5(encoded_string)\n",
        "\n",
        "    # Return the hexadecimal representation of the hash\n",
        "    return md5_hash.hexdigest()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74e6fd7a"
      },
      "source": [
        "def add_hashed_id(example):\n",
        "    # Rename the existing 'id' key to 'url'\n",
        "    example['url'] = example.pop('id')\n",
        "\n",
        "    # Extract question\n",
        "    question = example['question']\n",
        "\n",
        "    # Safely extract answer text\n",
        "    answers = example['answers']\n",
        "    answer_text = \"\"\n",
        "    if answers and answers['text']:\n",
        "        answer_text = answers['text'][0]\n",
        "\n",
        "    # Concatenate url, question, and answer_text\n",
        "    combined_string = example['url'] + question + answer_text\n",
        "\n",
        "    # Generate MD5 hash for the new 'id'\n",
        "    example['id'] = generate_md5(combined_string)\n",
        "\n",
        "    return example"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c86c8c67",
        "outputId": "557283a7-760d-452b-c10d-31d4a57ea81d"
      },
      "source": [
        "squad = squad.map(add_hashed_id)\n",
        "print(\"Dataset 'squad_final' updated with new hashed IDs and 'url' fields.\")\n",
        "print(squad)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 'squad_final' updated with new hashed IDs and 'url' fields.\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers', 'url'],\n",
            "        num_rows: 5003\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding test and validation sets..."
      ],
      "metadata": {
        "id": "KXQIhKcGOKDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Split the original 'train' split into:\n",
        "# 90% for new 'train' and 10% for 'temp_test'\n",
        "squad_temp = squad[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
        "print(\"Initial split (train and temp_test):\")\n",
        "print(squad_temp)\n",
        "\n",
        "# 2. add validation\n",
        "squad_final = squad_temp[\"train\"].train_test_split(test_size=0.0625, seed=42) # 5%\n",
        "squad_final[\"validation\"] = squad_final.pop(\"test\")\n",
        "squad_final[\"test\"] = squad_temp[\"test\"]\n",
        "\n",
        "print(\"Final dataset splits (train, validation, test):\")\n",
        "print(squad_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRaN_DdgOJKT",
        "outputId": "0fbb52d0-fa55-4a16-eda9-4a5798bd4e99"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial split (train and temp_test):\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers', 'url'],\n",
            "        num_rows: 4502\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers', 'url'],\n",
            "        num_rows: 501\n",
            "    })\n",
            "})\n",
            "Final dataset splits (train, validation, test):\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers', 'url'],\n",
            "        num_rows: 4220\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers', 'url'],\n",
            "        num_rows: 282\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers', 'url'],\n",
            "        num_rows: 501\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "rnd = random.randint(0, len(squad_final[\"train\"]))\n",
        "rnd, squad_final[\"train\"][rnd]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4zQ3M1FxPE8",
        "outputId": "bc8fd034-e66b-4c8f-c27f-402e9bdb22ab"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(204,\n",
              " {'id': 'f3f56b399a315e4feefe2482668a2c1d',\n",
              "  'title': 'PukarÃ£',\n",
              "  'context': 'PUKARÃƒ GUARANÃME â€“ CHISTES EN GUARANI\\n\\nPERURIMA\\n(Omombeâ€™Ãºva: MiguelÃ¡ngel Meza - Luque)\\nOguapÃ½ndajeko mbohapy paâ€™i peteÄ© asaje okaru haguáº­, tuichaichÃ¡va soâ€™o kaâ€™áº½ henondepekuÃ©ra ha upeichahÃ¡gui ohecha sapyâ€™a PerurimÃ¡me oÃºrÃµ ha heâ€™i ojupe: \"Ã‘ahenoimÃ­na PerÃºpe okaruhaguÃ¡icha guaâ€™u Ã±ane ndive ha Ã±aÃ±embohorymi heseâ€.\\n\\nHi\\'aguimÃ¡vo Perurima oÃ±eâ€™áº½mondo chupe peteÄ© paâ€™i: â€œPeru, ejÃºpy oremoirÇ”, jakaru oÃ±ondiveâ€.\\n\\nOja Peru ha oguapÃ½mavoi. Ojesareko ha ohecha mbohapÃ½nte oÃ® soâ€™o kaâ€™Ãª. OsÃª heâ€™i paâ€™i Leu: â€œJajovasÃ¡\\n\\nPa\\'i Leu he\\'i - En el nombre del Padre ha ipojÃ¡ima so\\'o rehe, Pa\\'i Tani he\\'i en el nombre del hijo ha ipojÃ¡ima ambuere - Perurima ohechÃ¡vo ivaÃ­taha hendive ha oÃ±e\\'áº½ mboyve Pa\\'i Livo osáº½ he\\'i - ou mboyve Espiritu Santo ha\\'Ãºtama che kÃ³va ha ipojÃ¡i so\\'o ka\\'áº½re ha\\'e raáº½. Ha pÃ©icha Peru oÃ±embohory jey Pa\\'ikuÃ©rare.\\n\\nKORAPÃPE\\n(Omombeâ€™Ãºva: Delia Audona Olivera - Kapiata)\\nKachÃ­ke ojupi aviÃ³n-pe, oiko chugui co-piloto. PeichahÃ¡guinte, ohendu hikuÃ¡i ayvu guasu: opukÃ¡va, osapukÃ¡iva hambaâ€™e. Nimboraâ€™e umi pasajero apytÃ©pe oÃ¯ peteÃ¯ hiâ€™arambotÃ½va ha haâ€™etÃ©pe opavave opurahÃ©i chupe â€œterevyâ€™aitÃ©keâ€ ha ojepopetejoa chupe.\\nPiloto heâ€™i KachÃ­kepe: â€œTereho emokirirÃ¯ umÃ­vapeâ€. KachÃ­ke, oÃ±emonde kate asÃ½va, oho ha uperiremÃ­nte oujeÃ½ma ha heâ€™i: â€œOÃ¯ma ne rembijerure mi coandanteâ€. \\n\\nAÃ±etehÃ¡pe, piloto ohechakuaa opahague ayvu. UpÃ©marÃ¶ oporandu KachÃ­kepe: â€œMbaâ€™Ã©ichapiko remokirirÃ¯ chupekuÃ©raâ€.\\nKachÃ­ke ombohovÃ¡i: â€œAha ha haâ€™e chupekuÃ©ra: pende ayvÃºtaramo tapehopa korapÃ½pe ha aipeâ€™a pe okÃ« ha amondopaite chupekuÃ©ra korapÃ½peâ€ (Nimboraâ€™e -oikuaaporÃ¤â€™á»¹re- oity aviÃ³n-gui chupekuÃ©ra)\\n\\n3 LEONES\\n(Omombeâ€™Ãºva: Silvia Cardozo Vda. de NÃºÃ±ez â€“ San Antonio)\\nKachÃ­ke ogÌƒuahÃ« peteÃ¯ Ã³gape. OÃ±emboâ€™y, omaÃ±a kyhyje Ã¡pe ha pÃ©pe, ha upÃ©i ojepopete. OsÃ« Ã³ga jÃ¡ra ha KachÃ­ke heâ€™i chupe: â€œNderekÃ³ipiko tres leonesâ€.\\n\\nÃ“ga jÃ¡ra ombohovÃ¡i KachÃ­kepe: â€œHÃ«e, areko tres leonesâ€.\\nKachÃ­ke osÃ« heâ€™i chupe: â€œNdaikatuichÃ©nepiko eÃ±apytimi mbohapyvÃ©pe, tahasa nde korapy rupi ha upÃ©i epoijey chuguikuÃ©raâ€\\n\\nOKAâ€™ÃšVA\\n(Omombeâ€™Ãºva: Sabina de la Cruz NÃºÃ±ez Cardozo - Kapiata)\\nOkaâ€™Ãºva oike Ã±emuhÃ¡me ha heâ€™i: â€œAipota 10 lÃ­tro guariâ€.\\nâ€œMoÃ¶pa oÃ¯ hyrurÃ¤â€, heâ€™i chupe Ã±emuha jÃ¡ra.\\nHa pe okaâ€™Ãºva heâ€™i: â€œHendivevoi reÃ±eâ€™Ã«reÃ­naâ€.\\n\\nADIVINADOR\\n(Omombeâ€™Ãºva: Paublino Carlos Ferreira QuiÃ±Ã³nez â€“ Fndo. de la Mora)\\nKachÃ­ke ojupi oikytÃ¯ hagÌƒua yvyra rakÃ¤. Upe jave ohasa upÃ©rupi Kalo ha heâ€™i chupe â€œReâ€™Ã¡ta upÃ©gui reikytÃ¯rÃ¶ yvyra nde py jokohaâ€.\\nAÃ±etehÃ¡pe, Kalo heâ€™ipÃ¡vo pÃ©ango, KachÃ­ke hoâ€™a ha oÃºmakatu heseve yvÃ½pe.\\n\\nUpÃ©rÃ¶, KachÃ­ke -ojehÃºvo hese Kalo heâ€™ivaâ€™ekue chupe ojehutaha hese- osÃ« heâ€™i KalÃ³pe: â€œNdÃ©ngo adivinador-raâ€™eâ€\\n\\nTUICHAITE LEMBÃšRE\\n(Omombeâ€™Ãºva: Rudi Torga - ParaguaÃ½pe)\\nMokÃ¶i okaâ€™Ãºva -tuichaite lembÃºre- ijurujÃ¡i omaÃ±a yvate gotyo. PeteÃ¯ heâ€™i hina: â€œAmÃ³va Jasyâ€. Ambue katu heâ€™i: â€œNahÃ¡niri. PÃ©va kuarahyâ€.\\n\\nPÃ©icha oÃ¯ hÃ­na mokÃ¶ive. Upe jave ohasa upÃ©rupi ambue okaâ€™Ãºva. UpÃ©marÃ¶ heâ€™i hikuÃ¡i chupe: â€œEmyesakÃ¤mÃ­na orÃ©ve peteÃ¯ mbaâ€™e... kuarahy tÃ©rÃ¤ jasÃ½pa pe ohesapÃ©vahinaâ€.\\n\\nPe ohasÃ¡va heâ€™i chupekuÃ©ra: â€œNdaikuaÃ¡i. ChÃ©ngo ndahaâ€™eivoi arupiguaâ€.\\n\\nY REMBEâ€™ÃPE\\n(Omombeâ€™Ãºva: Sabino GimÃ©nez Ortega: Aravoâ€™i - TovatÄ©) \\nMokÃ¶i kachÃ­ke oÃ¯ hÃ­na y rembeâ€™Ã½pe. PeteÃ¯va omoinge ipy ysyrÃ½pe ha ambuÃ©va katu omoinge ipo ysyrÃ½pe.\\nPeteÃ¯ karai omaÃ±Ã¡va hesekuÃ©ra oporandu mokÃ¶ivÃ©ape: â€œMbaâ€™Ã©iko pejapopeÃ­naâ€.\\n\\nPeteÃ¯ kachÃ­ke ombohovÃ¡i chupe kÃ³icha: â€œRo-pesca-hÃ­naâ€. Pe karai heâ€™ijey chupekuÃ©ra: â€œHa... mbaâ€™Ã©ichapiko pe-pescÃ¡-ta pÃ©ichaâ€.\\nUpÃ©marÃ¶, ambue kachÃ­ke omyesakÃ¤ chupe: â€œHa... chÃ©ngo che py sevoâ€™i ha haâ€™Ã©katu ipo pindaâ€.\\n\\nOVETÃ„ APUâ€™A\\n(Omombeâ€™Ãºva: Edgar David Galeano NÃºÃ±ez - Kapiata)\\nTani oho guaâ€™i retÃ¤me ha heta omaÃ±a rire, ojuhu ovetÃ¤ oÃ¯mÃ­va guive ijapuâ€™aha. \\nOporandu mbaâ€™Ã©repa ovetÃ¤ oÃ¯miva guive ijapuâ€™a ha peteÃ¯ guaâ€™i ombohovÃ¡i chupe kÃ³icha: â€œKuarahy ija porÃ¤ hagÌƒua ore rÃ³gapeâ€\\n\\nEMPERADOR\\n(Omombeâ€™Ãºva: Bernardo Luis Acevedo - Luque)\\nKachÃ­ke niko oho Buenos Aires-pe ombaâ€™apÃ³vo. Ohasa umi Ã¡ra ha ohaÃ­jepi ipehÃ«nguekuÃ©rape. PeteÃ¯ Ã¡ra ogÌƒuahÃ« isÃ½pe peteÃ¯ kuatiaÃ±eâ€™Ã« ha ipÃ½pe KachÃ­ke omombeâ€™u isymÃ­me oikohague chugui Emperador, Buenos Aires-pe. Tuicha vyâ€™Ã¡ngo oiko hÃ³gape. Sapyâ€™aite gÌƒuarÃ¤ oparupietÃ©ma ojekuaa upe mbaâ€™e guasuete.\\n\\nAre rire, peteÃ¯ koâ€™Ã«me, KachÃ­ke ogÌƒuahÃ«sapyâ€™a hÃ³gape. OsÃ«ngo opavavÃ©va ohugÌƒuatÃ¯ chupe. Ovyâ€™ajo\\'aitÃ©ngo umi ipehÃ«nguekuÃ©ra.\\nOhecharamÃ³vo chupe umi ipehÃ«ngukuÃ©ra ha opavave iÃ±irÃ¼ ojapo hikuÃ¡i chupe opaichagua vyâ€™aguasu: purahÃ©i, jeroky, kÃ¡so hambaâ€™e. PÃ©icha avei oiko karu guasu ha oÃ±emboyâ€™u guari tuichahÃ¡icha.\\n\\nPeichahÃ¡pengo peteÃ¯va oporandu chupe: â€œMbaâ€™eichakue piko oiko kuri ndehegui Emperadorâ€, ha KachÃ­ke ombohovÃ¡i: â€œHa peteÃ¯ Ã¡ra niko ajuhu che mbaâ€™apo pyahurÃ¤ ha upÃ©pe aikÃ©vo niko che patrÃ³n pyahu heâ€™i chÃ©ve: ndehegui oikÃ³ta emperador ko Ã¡ra guive. PÃ©ichanteâ€.\\nOsÃ«jey peteÃ¯ hapicha heâ€™i chupe: â€œAjÃ©pa ndepoâ€™Ã¡ite. Haâ€™e... oiko  rire ndehegui Emperador piko mbaâ€™e rejapoâ€\\nKachÃ­ke osÃ« upÃ©pe heâ€™i chupekuÃ©ra: â€œHa mbaâ€™Ã©piko reipota ajapo... ambohyru pÃ©ra, koâ€™Ã« guive pyhare peveâ€.\\n\\nMBOHAPY IMEMBY\\n(Omombeâ€™Ãºva: SalomÃ³n Melgarejo - ParaguaÃ½pe)\\nPeteÃ¯ kuÃ±akarai niko mbohapyvoi imemby. PeteÃ¯ Ã¡ra, oÃ±emongeta hendive peteÃ¯ karai oporandÃºva kuÃ±akaraimÃ­me mbaâ€™Ã©pa oikÃ³ta imembykuÃ©ragui okakuaapÃ¡vo.\\n\\nKuÃ±akarai, ohechaukÃ¡vo imemby tuichavÃ©va, heâ€™i: â€œKÃ³vagui oimevaâ€™erÃ¤ oikÃ³ta futbolista mbaâ€™eâ€. â€œAnichÃ©ne. Mbaâ€™Ã©repa ereâ€, heâ€™i chupe upe karai. KuÃ±akarai ombohovÃ¡i chupe: â€œHaâ€™e... haâ€™Ã©ngo opay guive, oke peve oiko pelota rapykuÃ©riâ€.\\nOhendÃºvo upe mbaâ€™e, karai oporandujey: â€œHa amÃ³va, mbyterÃ©va, pÃ©vagui piko mbaâ€™e oikÃ³taâ€. KuÃ±akarai omaÃ±Ã¡vo imemby mbyterÃ©re heâ€™i: â€œHaâ€™e... pÃ©vagui oimevaâ€™erÃ¤ oikÃ³ta mÃºsico mbaâ€™eâ€. â€œAnichÃ©ne. Ha... mbaâ€™Ã©repiko ereâ€, heâ€™i chupe upe karai. KuÃ±akarai ombohovÃ¡i chupe: â€œHaâ€™e... haâ€™Ã©ngo opay guive, oke peve oiko opurahÃ©i ha ombopu imbarakaâ€™iâ€.\\n\\nOhendupÃ¡vo upe mbaâ€™e, karai oporandujey: â€œHa amÃ³va, pe ipahaguÃ©va, pÃ©vagui piko mbaâ€™e oikÃ³taâ€. KuÃ±akarai omaÃ±Ã¡vo imembyâ€™i pahaguÃ©re heâ€™i: â€œHaâ€™e... pÃ©vagui oimevaâ€™erÃ¤ oikÃ³ta polÃ­tico mbaâ€™eâ€. â€œAnichÃ©ne. Ha... mbaâ€™Ã©reiko ereâ€, heâ€™i chupe upe karai. KuÃ±akarai ombohovÃ¡i chupe: â€œHaâ€™e... pÃ©vango rehupÃ­vo Ãºpa... okakÃ¡ma ndereheâ€.\\n\\nMUAMUA\\n(Omombeâ€™Ãºva: Paternio Emiliano Vera GonzÃ¡lez - Villarrica)\\nPeteÃ¯ pyhare mokÃ¶i guaâ€™i omonda peteÃ¯ tujaâ€™Ã­pe ha pya\\'Ã©peko oike hikuÃ¡i kaâ€™aguÃ½re ha oÃ¯makatu omuÃ±Ã¡va chupekuÃ©ra.\\nKaâ€™aguÃ½pe oÃ¯ heta muamua hendy ha oguÃ©va. Nimboraâ€™e umi guaâ€™i ndoikuaaivavoi mbaâ€™Ã©pa muamua, upÃ©vare peteÃ¯va osÃ« osapukÃ¡i hapichÃ¡pe: â€œÂ¡Pyaâ€™Ã©ke, che irÃ¼. Ejeity yvÃ½pe!â€.\\n\\nâ€œMbaâ€™Ã©repikoâ€, oporandu chupe hapicha.\\n\\nâ€œHa... nderehechÃ¡ipiko. Ã‘atiâ€™Ã¼ jepe Ã±ande reka linterna reheveâ€.\\n\\nITA GUASU\\n(Omombeâ€™Ãºva: Celso VelÃ¡zquez - ParaguaÃ½pe)\\nKachÃ­ke ohaâ€™ahÃ­na partÃ­do, kaâ€™arupytu. UpÃ©ingo iÃ±ipytÃ¼etenungÃ¡ma ha mbaâ€™evÃ©ma ndojehechavÃ©i.\\nPeichahÃ¡guinte KachÃ­ke oho heseve ha osapukÃ¡i â€œpejeÃ­ke che rapÃ©guiâ€, ha ohupytÃ½vo, hatÃ¤iterei oinupÃ¤ pe pelÃ³ta ha KachÃ­ke omopÃ«mi ipy. Nimboraâ€™e pelÃ³ta osÃ«kuri okÃ¡pe ha hendaguÃ©pe KachÃ­ke opyvoÃ­kuri peteÃ¯ ita guasu.\\nIÃ±irÃ¼nguÃ©ra niko ohupi hikuÃ¡i KachÃ­kepe ijyva Ã¡ri ha ogueraha chupe hÃ³gape.\\n\\nKachÃ­ke niko hasÃ«rÃ¤ngue, opuka omanÃ³ta. PeteÃ¯va oporandu chupe: â€œMbaâ€™Ã©repiko repuka, nerasÃ«rÃ¤ngueâ€.\\nâ€œChÃ©ngo amopÃ« che pÃ½nteâ€, ombohovÃ¡i chupe KachÃ­ke. â€œHa mbaâ€™e upÃ©va pikoâ€, heâ€™ijey chupe hapicha.\\n\\nKachÃ­ke osÃ« heâ€™i chupe: â€œNderehechasÃ©ipiko mbaâ€™Ã©ichapa oimÃ©ne hasÃ«hÃ­na upe o-cabecea-vaâ€™ekue. Ha... upÃ©vako pe chembopukÃ¡vahinaâ€.\\n\\nTROMBÃ“N\\n(Omombeâ€™Ãºva: Roque Jacinto Lovera - ParaguaÃ½pe)\\nGuaâ€™i ou ParaguaÃ½pe peteÃ¯ jerokyhÃ¡pe, Ã³ga ikatÃ©vape ha peichahÃ¡gui hyerasÃ½sapyâ€™a. Oporandu baÃ±o-re ha peteÃ¯ heâ€™i chupe: â€œAl fondo y a la derechaâ€.\\n\\t\\nNimboraâ€™e guaâ€™i ndoikuaaivavoi â€œbaÃ±o modernoâ€ ha oikÃ©nte peteÃ¯ koty iÃ±ipytÃ¼vape, opokopoko ha ojuhÃºvo pe mbaâ€™e apuâ€™a, oguapÃ½makatu ojapo ku jaikuaÃ¡va.\\n\\t\\nUpÃ©inte niko peteÃ¯ mÃºsico, pochy reheve, ou ha heâ€™i: â€œMÃ¡vapiko pe tavÃ½cho okakavaâ€™ekue che trombÃ³n-peâ€. \\n\\nPeteÃ¯ guaâ€™i oike kaâ€™aguÃ½pe ha upeichahÃ¡guinte peteÃ¯ guyra vaicha oÃ±eâ€™Ã«va chupe ha osapukÃ¡iva: â€œÂ¡guaâ€™a!â€.\\nNimboraâ€™e guaâ€™i ndoikuaaivavoi pe guyra hÃ©rava guaâ€™a ha ohendÃºvo guaâ€™a Ã±eâ€™Ã«, guaâ€™i osÃ« heâ€™i chupe, pochy reheve: â€œErÃ©rire guaâ€™i ne akÃ¤itÃ©pe rojapimoâ€™Ã¤â€\\n\\nRECREO\\n(Omombeâ€™Ãºva: Luis MartÃ­n Cuenca - ParaguaÃ½pe)\\nPeteÃ¯ Ã¡ra KachÃ­ke heâ€™i: â€œKoâ€™Ã«rÃ¶ guive ahÃ¡ta mboâ€™ehaÃ³pe, aÃ±emoaranduâ€. UpÃ©marÃ¶, umi mitÃ¤mimi oikÃ©mava mboâ€™ehaÃ³pe heâ€™i hikuÃ¡i chupe: â€œKachÃ­ke, anÃ­ke nderesarÃ¡i, reguerahavaâ€™erÃ¤ha mbaâ€™e reâ€™u hagÌƒua recreo-pe.\\n\\nAmbue Ã¡ra koâ€™Ã«me KachÃ­ke ohÃ³makatu mboâ€™ehaÃ³pe ha ogueraha hendive hembirekÃ³pe. Mboâ€™ehÃ¡ra oporandu chupe maâ€™erÃ¤pa ogueru hembirekÃ³pe.\\nKachÃ­ke ombohovÃ¡i chupe kÃ³icha: â€œHaâ€™u hagÌƒua recreo-peâ€\\n\\nTAPE\\nKachÃ­ke ou mombyrygui ha oikÃ©vo hÃ³gape, peteÃ¯ hapicha oporandu chupe: â€œKachÃ­ke, mbaâ€™Ã©ichapa oÃ¯hÃ­na Ã±ande rape. NdaivaietÃ©ipaâ€.\\nKachÃ­ke ombohovÃ¡i chupe: â€œChe ndaikuaÃ¡i. Che aju vereda rupiâ€\\n\\nMÃNGO\\n(Omombeâ€™Ãºva: Sabina de la Cruz NÃºÃ±ez Cardozo - Kapiata)\\nPeteÃ¯ Guaâ€™i ojupi peteÃ¯ parralÃ©ra Ã¡ri ha peteÃ¯ tapicha ohasÃ¡va upÃ©rupi oporandu chupe: â€œMaâ€™erÃ¤piko rejupi upÃ©peâ€. â€œHaâ€™u hagÌƒua mÃ¡ngoâ€, heâ€™i chupe guaâ€™i.\\n\\nTapicha heâ€™ijey guaâ€™Ã­pe: â€œMbaâ€™Ã©ichaiko reâ€™Ãºta mÃ¡ngo upÃ©pe, pÃ©vango Ãºvaâ€.\\nâ€œMÃ¡ngo haâ€™Ãºtaâ€, heâ€™ijeÃ½vo guaâ€™i onohÃ« i-bolsillo-gui peteÃ¯ mÃ¡ngo ha... hoâ€™u.\\n\\nCOCAâ€™I\\n(Omombeâ€™Ãºva: Pablino GÃ³mez Vera â€“ San Lorenzo;\\nha upÃ©i Serafina HaidÃ©e Villalba â€“ San Pedro del Parana)\\nLeÃ¶ ha juâ€™i oike hikuÃ¡i peteÃ¯ Ã±emuhÃ¡me. Kaâ€™i -haâ€™Ã©va Ã±emuha jÃ¡ra- omomatei chupekuÃ©ra ha upÃ©i oporandu: â€œMbaâ€™Ã©pa peâ€™Ãºtaâ€. Juâ€™i ojerure guari ha LeÃ¶ katu heâ€™i: â€œChe, Cocaâ€™Ã­nte haâ€™Ãºtaâ€. \\n\\nKaâ€™i ohendÃºvo upÃ©va, oÃ±emondÃ½i ha ombovu kamisa lÃ³mo, oimoâ€™Ã¤gui LeÃ¶ oÃ±eâ€™Ã«ha hese.\\n(LeÃ¶ niko Coca Cola michÃ¯vante raâ€™e pe hoâ€™usÃ©va, ndahaâ€™Ã©i Ã±ane irÃ¼ kaâ€™Ã­pe)\\n\\nPALANCA DE CAMBIO\\n(Omombeâ€™Ãºva: AbdÃ³n Galeano BenÃ­tez - Kapiata)\\nPeteÃ¯ Ã¡ra KachÃ­ke, oikÃ³va KuruguatÃ½pe, heâ€™i: â€œChe ndaikuaai koâ€™Ã¡gÌƒa peve Ciudad del Este, upÃ©vare asÃ«ta ha aha aikuaami hagÌƒuaâ€, ha upehague koâ€™Ã«me KachÃ­ke osÃ«sapyâ€™a kaâ€™aguÃ½gui. Haâ€™Ã©ngo ndoikuaÃ¡iva ko ParaguÃ¡y, imitÃ¤ guive ha ikaraipa peve niko kaâ€™aguÃ½pentevoi oiko. NosÃ«ivavoi upÃ©gui. UpÃ©vare avei mokÃ¶i hapicha osÃ«mavaâ€™ekue kaâ€™aguÃ½gui ohekomboâ€™e chupe ha omombeâ€™u chupe mbaâ€™Ã©pa ojapovaâ€™erÃ¤. Omombeâ€™u chupe ojupivaâ€™erÃ¤ha Rysa-pe, ohepymeâ€™Ã«vaâ€™erÃ¤ha ipasaje hambaâ€™e...\\n\\nOsÃ« javete tapehÃ¼me ogÌƒuahÃ« avei mbaâ€™yrumá»¹i Rysa-pegua. KachÃ­ke -ikate asÃ½va, icorbataâ€™ipÃ¡va- ojupi, ohepymeâ€™Ã« ipasaje ha oguapy mbaâ€™yru mboguatahÃ¡ra ykete. UpÃ©ingo, KachÃ­ke omaÃ±Ã©jepi mbaâ€™yru mboguatahÃ¡ra omomá»¹i jave pe palanca de cambio. Haâ€™Ã©â€™angango ndoikuaaivavoi mbaâ€™Ã©pa upe mbaâ€™e ha ojepyâ€™ap  Ã±epyrÃ¼.\\n\\t\\nAre oho rire, mbaâ€™yrumá»¹i opyta ha mbaâ€™yru mboguatahÃ¡ra oipeâ€™a okÃ« ha heâ€™i: â€œKuÃ±akarai ha karaikuÃ©ra koâ€™Ã¡pe japytuâ€™Ãºta 15 minutos ha upÃ©i jahajeÃ½taâ€ ha oguejypaite hikuÃ¡i.\\n\\t\\nUpÃ©ingo ojupipajey mbaâ€™yrumá»¹ime ha ipahaÃ­tÃ©pe ojupi pe mbaâ€™yru mboguatahÃ¡ra ha haâ€™e oguapÃ½vo ndojuhuvÃ©isapyâ€™a ipalanca de cambio. Oheka oparupiete, ijapykaguÃ½pe jepeve ha ndojuhÃºi mamove. UpÃ©marÃ¶ KachÃ­ke oporandu chupe: â€œMbaâ€™Ã©iko okaÃ±y ndehegui, karaiâ€, ha tapicha ombohovÃ¡i chupe: â€œche palanca de cambioâ€.\\n\\t\\nKachÃ­ke ojaivy, ohupi ipÃ³pe upe palanca de cambio haâ€™e onohÃ« ha oÃ±ongatuvaâ€™ekue ha heâ€™i mbaâ€™yru mboguatahÃ¡rape: â€œKÃ³vapiko. Ku ujeâ€™ietÃ©ma renohÃ«sevaâ€™ekuÃ©piko. Naâ€™Ã¡pe che anohÃ«ma ndÃ©veâ€.\\n\\nMÃVAPIKO OJOKÃ“TA\\n(Omombeâ€™Ãºva: AbdÃ³n Galeano BenÃ­tez - Kapiata)\\nMbaâ€™yru mboguatahÃ¡ra omoÃ¯jey hendagÌƒuÃ¡me ipalanca de cambio ha mbaâ€™yrumá»¹i okuâ€™ejey. KachÃ­ke ohÃ³makatu Ciudad del Este-pe. MbeguakatÃºpe mitÃ¤ Rysa henyhÃ« ohÃ³vo. NahembyvÃ©ima apyka ojeguapy hagÌƒua. PeichahÃ¡gui ojupi peteÃ¯ kuÃ±a hyeguasÃºva ha KachÃ­ke opuâ€™Ã¤voi omeâ€™Ã« chupe ijapyka. \\n\\t\\nKachÃ­ke omaÃ±a ha ojuhu opavave oÃ±emboâ€™Ã½va niko ojejoko peteÃ¯ yvyrapukÃºre. UpÃ©marÃ¶ haâ€™e avei oÃ±emoÃ¯ ijykerekuÃ©ra ha ojejoko upe yvyrÃ¡re. MbeguekatÃºpe inandijey upe mbaâ€™yrumá»¹i ha oÃ¯ma avei heta apyka inandÃ­va ojeguapy hagÌƒua, haâ€™e... KachÃ­ke katu ndoguapÃ½i. HatÃ¤ngo ojejoko yvyrapukÃºre. \\n\\t\\nMbaâ€™yru mboguatahÃ¡ra ojepyâ€™apÃ½ma hese ha osÃ« heâ€™i chupe: â€œKachÃ­ke, eguapÃ½na, anivÃ©na nekaneâ€™Ã¶reiâ€ ha KachÃ­ke tovasÃ½re ombohovÃ¡i chupe: â€œEâ€™a, ha che aguapÃ½ropiko mÃ¡va ojokovÃ©ta ko yvyrapukuâ€.\\n\\nTÃ SYRY\\n(Omombeâ€™Ãºva: Cecilio RamÃ³n Coronel GÃ³mez â€“ Kaâ€™aguasu)\\nPeteÃ¯ mitÃ¤â€™i hoâ€™uhÃ­na itÃ¯syry ha heindy ohechÃ¡vo chupe pÃ©icha, oho heâ€™i isÃ½pe: â€œMamÃ¡, mamÃ¡, Lui hoâ€™uhÃ­na itÃ¯syryâ€.\\nIsy pochy reheve ou heâ€™i LuÃ­pe: â€œMbaâ€™Ã©repiko nere-convida-i ne hermano-peâ€.\\n\\nHAGUÃ‰RE\\n(Omombeâ€™Ãºva: Serafina HaidÃ©e Villalba â€“ San Pedro del Parana)\\nKachÃ­ke niko ivareâ€™a korÃ³cho oÃºvo ha saâ€™i ipirapire. UpÃ©ingo, pe ivareâ€™ave jave, ojuhÃºsapyâ€™a hapÃ©pe peteÃ¯ Ã±emuha, ojehepymeâ€™Ã«hÃ¡pe ryguasu kaâ€™Ã«. \\n\\nKachÃ­kengo hesajere ha hendysyrypa omaÃ±Ã¡vo umi ryguasu kaâ€™Ã« ojereâ€™asÃ½vahÃ­na, ojehesy aja. Pyaâ€™Ã©ko, pyâ€™a kororÃ¶re, KachÃ­ke oÃ±emboja ha oporandÃºma Ã±emuha jÃ¡rape mboÃ½pa hepy umi ryguasu kaâ€™Ã«.\\nÃ‘emuha jÃ¡ra heâ€™i chupe: â€œ20.000â€.\\n\\nOhendÃºvo pÃ©va, KachÃ­ke heâ€™i chupe: â€œChÃ©ngo areko 10.000 manteâ€.\\nUpÃ©pe Ã±emuha jÃ¡ra heâ€™i KachÃ­kepe: â€œOÃ¯ma. Ameâ€™Ã«ta ndÃ©ve haguÃ©re...â€\\nPÃ©va ohendÃºvo KachÃ­ke heâ€™i: â€œMbaâ€™Ã©ichapiko haâ€™Ãºta hague  reheveâ€\\n\\nARCO\\n(Omombeâ€™Ãºva: Rudi Torga - ParaguaÃ½pe)\\nKachikekuÃ©ra ou ParaguaÃ½pe ha oho hikuÃ¡i ohecha aipo partido, Olimpia ha Cerro PorteÃ±o ohaâ€™Ã¤va. Haâ€™ekuÃ©ra niko ndoikuaÃ¡ivavoi upe mbaâ€™e hÃ©rava fÃºtbol, jepÃ©mo upÃ©icha, hesahojoa omaÃ±a mbaâ€™Ã©ichapa heta tapicha ikÃ¼ okÃ¡pe, itavÃ½vaicha, omuÃ±a hikuÃ¡i pe mbaâ€™eâ€™apuâ€™a. Opa rire ohendu hikuÃ¡i peteÃ¯ heâ€™Ã­va: â€œOlimpia ganÃ³ dos a ceroâ€. OjevÃ½vo hekohÃ¡pe, haâ€™ekuÃ©ra heâ€™i hikuÃ¡i: â€œKoâ€™Ã«ro, Ã±ande avei jajapomÃ­ta upe jahechavaâ€™ekue, jahechÃ¡pa mbaâ€™e Ã±aÃ±anduâ€.\\n\\nKoâ€™Ã«mbamÃ­vo oÃ±epyrÃ¼ma ohaâ€™Ã¤ hikuÃ¡i. OhoreÃ­ngo heseve hikuÃ¡i. Ohasa rire mokÃ¶i aravo, peteÃ¯va -nohaâ€™Ã¤iva, oÃ¯va okÃ¡pe- osapukÃ¡i chupekuÃ©ra: â€œPepytuâ€™umÃ­na ha peju perambosaâ€ ha osÃ« peteÃ¯ KachÃ­ke ombovÃ¡i chupe: â€œNdaikatÃºi, cero a cero guetereiâ€ ha otuâ€™u ojuehe, omuÃ±a ipyâ€™aropÃºvaicha pe mbaâ€™eâ€™apuâ€™a.\\n\\nAsajetÃ©vo, osÃ«jeyma peteÃ¯va osapukai chupekuÃ©ra: â€œPepytuâ€™umÃ­na ha peju pekaruâ€ ha osÃ«jeÃ½ma peteÃ¯ KachÃ­ke heâ€™i: â€œNdaikatÃºi, cero a cero guetereiâ€ ha ombovu hikuÃ¡i kamisa lÃ³mo mbaâ€™eâ€™apuâ€™a rapykuÃ©ri.\\n\\nIÃ±ipytÃ¼ javete niko peteÃ¯va osapukÃ¡ijeÃ½ma chupekuÃ©ra: â€œPepytuâ€™umÃ­na ha peju peâ€™u kojÃ³i mbejÃºreâ€ ha peteÃ¯ KachÃ­ke otyryrÃ½va mbaâ€™eâ€™apuâ€™a rapykuÃ©ri, ikÃ¼sÃ«mbÃ¡va ha hesajerepÃ¡mava, heâ€™ijey: â€œNdaikatÃºi, cero a cero guetereiâ€.\\n\\nUpÃ©marÃ¶, tapicha oÃ¯va okÃ¡pe, pochy reheve, osapukÃ¡i chupekuÃ©ra: â€œMbaâ€™Ã©ichapiko cero a cero-ta, ko koâ€™Ã«ti guive pehaâ€™Ã¤vapeÃ­naâ€. Ha osÃ« KachÃ­ke Santacruz ombohovÃ¡i chupe: â€œHaâ€™e... mbaâ€™Ã©ichapiko reipota romoinge upe gol, ndaore-arco-iningoâ€.\\n\\nTIRO LIBRE\\n(Omombeâ€™Ãºva: Rudi Torga - ParaguaÃ½pe)\\nAmbue Ã¡ra koâ€™Ã«me, KachikuÃ©ra oÃ±emoÃ¯jey peteÃ¯ Ã±eâ€™Ã«me ha ohaâ€™Ã¤jey peteÃ¯ partido. UpearÃ¤ omoÃ¯ma hikuÃ¡ hiâ€™arco-rÃ¤.\\nOhaâ€™Ã¤hÃ­na hikuÃ¡i ha peichahÃ¡guinte peteÃ¯ opyvoi hapichÃ¡re. KachÃ­ke Refere osapukÃ¡i: â€œTiro libreâ€. Omohenda pe mbaâ€™eâ€™apuâ€™a ha oÃ±epyrÃ¼ oguata henonde gotyo ha oipapa, upÃ©i KachÃ­ke Refere opyta, ohechauka ikuâ€™Ã¤me ha heâ€™i: â€œAquÃ­ la barreraâ€. UpÃ©marÃ¶ irundy tapicha ojapÃ³makatu upe barrera. KachÃ­ke Romerito oguevi ha ou heseve opyvoihagÌƒuÃ¡icha mbaâ€™eâ€™apuâ€™Ã¡re. Upe javete umi irundy, oÃ¯va barrera-pe, ojere ha omaÃ±a hiâ€™arco gotyo. KachÃ­ke Refere ombopu ituru ha heâ€™i irundyvÃ©vape: â€œMbaâ€™Ã©piko pÃ©va. Maâ€™erÃ¤piko pejereâ€ ha KachÃ­ke Gamarra, oÃ¯va barrÃ©ra-pe, ombohovÃ¡i chupe: â€œHaâ€™e... orÃ©niko rohechase avei pe gol oike javeâ€.\\n\\nMBÃ“I\\n(Omombeâ€™Ãºva: Porfiria Orrego Invernizzi â€“ San Lorenzo)\\nPeteÃ¯ Ã¡ra KachÃ­ke ohepymeâ€™Ã«se hÃ³ga. Pyaâ€™Ã©voi ojuhÃºmakatu ojoguasÃ©va chugui. OgÌƒuahÃ« hikuÃ¡i peteÃ¯ Ã±eâ€™Ã«me ha upehague koâ€™Ã«me oho hikuÃ¡i escribanÃ­a-pe. \\n\\nUpÃ©pe karai escribano ojejapo chupekuÃ©ra pe kuatia. UpÃ©i oguapy pe karai ojoguÃ¡tava ha ohai heraguapy.\\nUpÃ©ingo oguapy KachÃ­ke ohai hagÌƒua heraguapy. Oipyhy pe haiha ha oÃ±epyrÃºmakatu ohai. IpukÃºngo pe ijehai, ohaivÃ©rÃ¶ke ohai. OjapÃ³ngo peteÃ¯ raya ipukurasÃ¡va.\\n\\nOhechÃ¡vo upÃ©va, karai escribano ojepyâ€™apy ha oporandu KachÃ­kepe mbaâ€™Ã©ichapa hÃ©ra, ha KachÃ­ke heâ€™i chupe: â€œChe cherÃ©ra mbÃ³iâ€.\\n\\nNDACHEKUAAVÃ‰IMAPIKO\\n(Omombeâ€™Ãºva: Carmen Ramona Caballero de Vera â€“ General Aquino)\\nKachÃ­ke oike korapy ahÃ©nope, ojupi narÃ¤ha rakÃ¤re ha oipoâ€™o hiâ€™a. UpÃ©i ijÃ¡ra ohecha chupe ha heâ€™i: â€œEguejy chÃ©ve upÃ©guiâ€.\\nUpÃ©i, oguejy rire yvÃ½pe, karai oporandu chupe: â€œMÃ¡vaiko ndeâ€.\\n\\nKachÃ­ke heâ€™i: â€œEâ€™a... ndachekuaavÃ©imapiko. ChÃ©ngo pe angete aimeâ€™akue amo yvateâ€.\\n\\nDISJOCKEY\\n(Omombeâ€™Ãºva: Javier ArÃ©valos Morel â€“ San Juan Nepomuceno)\\nMokÃ¶i KachÃ­ke omokÃ¶hÃ­na bar-pe ha ohendu hikuÃ¡i opaichagua purahÃ©i peteÃ¯ radio rupive. UpÃ©inte ndaipuvÃ©i pe radio ha oporandu hapichÃ¡pe mbaâ€™Ã©pa ojehu chupe.\\n\\nKachÃ­ke ovichea ha ojuhu pe radio ryepÃ½pe peteÃ¯ tarave reâ€™Ã¶ngue ha upÃ©marÃ¶ osÃ« heâ€™i iÃ±irÃ¼me: â€œOmanÃ³mboraâ€™e Ã±ande radio disjockeyâ€.\\n\\nOMONDÃIRAMO GUARE VAKÃPE\\n(Omombeâ€™Ãºva: Roque Jacinto Lovera - ParaguaÃ½pe)\\nPeteÃ¯ KachÃ­ke oike ombaâ€™apo peteÃ¯ Paraguayo ndive. PÃ©va heâ€™i chupe: â€œPeteÃ¯ mbaâ€™Ã©nte nde rejapÃ³ta. ReÃ±angarekÃ³ta amo che yvyotyty, ani hagÌƒua vakakuÃ©ra hoâ€™upa umi che yvotymimi iporÃ¤porÃ¤itÃ©vaâ€.\\nâ€œHa mbaâ€™Ã©pa ajapovaâ€™erÃ¤â€, oporandu KachÃ­ke. \\n\\nâ€œHa vakÃ¡ oikÃ©vo che yvotytÃ½pe, nde remondÃ½ivaâ€™erÃ¤â€, heâ€™Ã­ chupe pe karai.\\nUpÃ©ingo, peteÃ¯ vaka ou oikÃ©sapyâ€™a pe yvotytÃ½pe ha KachÃ­ke ohÃ³makatu chupe, mbeguekatÃºmi ha kirirÃ¯haitÃ©pe. OÃ±embojapaite ha oÃ±eâ€™Ã« vakÃ¡pe, ijapysÃ¡pe, ha heâ€™i chupe: â€œVaka, vaka... nde sy oime omanoâ€. \\nUpÃ©i ou heâ€™i Ã³ga jÃ¡rape: â€œAmondÃ½i tuicha porÃ¤ chupe. Haâ€™Ã©ngo chupe isy omanohagueâ€.\\n\\nOMONDÃIRAMO GUARE RYGUASÃšPE\\n(Omombeâ€™Ãºva: Luz Edith GonzÃ¡lez de Segovia - Guajayvi)\\nKachÃ­ke oike ombaâ€™apo peteÃ¯ Paraguayo ndive. UpeichahÃ¡guiente upe Ã³ga jÃ¡ra heâ€™i KachÃ­kepe: â€œTerehomi emondÃ½i chÃ©ve amo ryguasuâ€. KachÃ­kengo oho mbeguekatumi ha peichahÃ¡guinte pe ryguasu ojere ha omaÃ±a porÃ¤ KachÃ­kere. UpÃ©maro haâ€™e ojevy ha heâ€™i Ã³ga jÃ¡rape: â€œNdaikatÃºi amondÃ½i ryguasÃºpeâ€. \\n \\nÃ“ga jÃ¡ra ohechapaitevaâ€™ekue upe ojehÃºva, oporandu chupe: â€œHa mbaâ€™Ã©repiko ndaikatÃºi remondÃ½i ryguasÃºpeâ€. \\nKachÃ­ke ombohovÃ¡i: â€œHa... mbaâ€™Ã©ichapiko reipota amondÃ½i, cherechajepÃ©manikoâ€.\\n\\nHÃ‰EEPA\\n(Omombeâ€™Ãºva: LucÃ­a Valiente GonzÃ¡lez â€“ Isla Puku)\\nPeteÃ¯ mitÃ¤â€™i hoâ€™uhÃ­na narÃ¤ha ahÃ©no ha peichahÃ¡gui ojuhu chupe ijÃ¡ra ha heâ€™i chupe: â€œHÃ©eepa...â€\\nMitÃ¤â€™i oÃ¯va narÃ¤ha rakÃ¤re ombohovÃ¡i chupe: â€œOÃ¯ hÃ©va ha ndahÃ©iva aveiâ€.\\n\\nPÃILA\\n(Omombeâ€™Ãºva: Augusto MartÃ­n Jara LÃ³pez - YÃ¼)\\nKachÃ­ke ojogua mokÃ¶i celular, peteÃ¯ imbaâ€™erÃ¤ ha ambuÃ©katu hembirekÃ³pe gÌƒuarÃ¤. PeteÃ¯ koâ€™Ã«me KachÃ­ke oho Kaâ€™aguasÃºpe. Oho mboyve, heâ€™i hembirekÃ³pe: â€œAgÌƒuahÃ«vo Kaâ€™aguasÃºpe rohenÃ³ita, jahechami mbaâ€™Ã©ichapa oiko koâ€™Ã¤ celularâ€, ha oho.\\nKaâ€™aguasu guive ohenÃ³i hembirekÃ³pe ha oporandu chupe â€œMbaâ€™Ã©iko rejaporeÃ­naâ€. Hembireko heâ€™i chupe: â€œAmbochyryryâ€™aÃ­na ryguasu rupiâ€™a, sombrero-peâ€.\\n\\nOhendÃºvo upÃ©va niko KachÃ­ke oÃ±emona yvÃ½re, opuka ipyâ€™aropÃºta ha heâ€™ijey hembirekÃ³pe: â€œMbaâ€™Ã©ichapiko rembochyryrÃ½ta sombrero-pe, maâ€™erÃ¤katupiko oÃ¯ pe pÃ¡ilaâ€.\\n\\nMOÃ–PA OHO KO TAPE\\n(Omombeâ€™Ãºva: Ligia Calonga â€“ Pedro Juan Caballero)\\nPeteÃ¯ karai ohasÃ¡va ohÃ³vo tapÃ©re, oporandu KachÃ­kepe: â€œMoÃ¶pa oho ko tapeâ€.\\nKachÃ­ke ombohovÃ¡i: â€œKo tape ndohÃ³i mamove, ndÃ©ngo pe rehovareÃ­naâ€.\\n\\nÃREA CHICA\\n(Omombeâ€™Ãºva: Cecilio RamÃ³n Coronel GÃ³mez â€“ Kaâ€™aguasu)\\nKachike oho Paraguaype. Ojupi lÃ­nea 15-pe ha he\\'i mbaâ€™yru mboguatahÃ¡rape: \"KÃ³vapio OHASA Olimpia cancha rupi?\". \"HÃ©Ã«\", ombohovai chupe mbaâ€™yru mboguatahÃ¡ra.\\n\\nUpÃ©marÃ¶ KachÃ­ke heâ€™i chupe: â€œChemboguejymÃ­na Ã¡rea chÃ­ca akÃ¤me ikatÃºrÃ¶â€.\\n\\nHATÃ„ITEREI AIPOKA\\n(Omombeâ€™Ãºva: Margarita Leiva â€“ San Lorenzo)\\nKachÃ­ke ombojahuhÃ­na imbarakaja ha peteÃ¯ karai ohasÃ¡va heâ€™i chupe: â€œKachÃ­ke, anÃ­tei embojahu ne mbarakajÃ¡pe, chÃ¡ke, omanÃ³ne ndeheguiâ€.\\n\\nAmbue Ã¡ra ohasÃ¡vo karai KachÃ­ke rÃ³ga renonde rupi, hesahÃ³sapyâ€™a KachÃ­kere ha ojuhu chupe hasÃ«hÃ­na. Nimboraâ€™e omano imbarakaja. OhechakuaÃ¡vo upe mbaâ€™e, pe karaimi heâ€™i KachÃ­kepe: â€œHaâ€™e porÃ¤ niko ndÃ©ve anive hagÌƒua rembojahu ne mbarakajÃ¡pe porque ojahogÃ¡ta ndeheguiâ€.\\n\\nKachÃ­ke, tasÃ«me, ombohovÃ¡i pe karaÃ­pe: â€œNdojahogÃ¡iniko... hatÃ¤itereÃ­nteko aipokÃ¡kuriâ€.\\n\\nMOÃ–PA OPYTA KACHÃKE RÃ“GA\\n(Omombeâ€™Ãºva: Sabina de la Cruz NÃºÃ±ez Cardozo - Kapiata)\\nPeteÃ¯ karai ogÌƒuahÃ« peteÃ¯ tÃ¡vape. OhupytÃ½vo peteÃ¯ Ã±emuha, ojuhu peteÃ¯ Ã±ande ypykue oguapÃ½va upe Ã±emuha renondÃ©pe, ha oporandu chupe: â€œNdÃ©pa reikuaa moÃ¶pa opÃ½ta KachÃ­ke rÃ³gaâ€. Haâ€™e ombohovÃ¡i chupe: â€œRehÃ³ta Ã¡pe, mombyry mombyry ha upÃ©i rejuhÃºta peteÃ¯ tajy kakuaa, tapepoâ€™i mbytetÃ©pe. UpÃ©pe rejerÃ©ta nda asu gotyo ha rehojeÃ½ta mombyry rehupyty peve peteÃ¯ yvyraro oÃ¯va avei tape mbytetÃ©pe. UpÃ©pe rejerÃ©ta nde akatÃºa gotyo ha reguatajeÃ½ta. UpÃ©i resyryrÃ½ta yvy gotyo peteÃ¯ ysyry peve, ha hembeâ€™Ã½pe rejuhÃºta peteÃ¯ tapá»¹i, rehasapÃ¡ta upÃ©va ha rejupÃ­ta petei yvyty ha Ã¡gÌƒa regÌƒuahÃ«vo huâ€™Ã¤me, rejerÃ©ta remaÃ±a nde atukupe gotyo ha rehechajeÃ½ta upe tapá»¹imi rehasavaâ€™ekue ysyry rembeâ€™Ã½pe... upÃ©va hÃ­na KachÃ­ke rÃ³gaâ€. \\n\\nKarai oho ha ojapopaite ojeâ€™Ã©vaâ€™ekue chupe. Are rire upe karai ojevy ha ohasajeÃ½vo Ã±emuha renonde rupi upe Ã±ande ypykue heâ€™i chupe: â€œKarai, KachÃ­ke ndaipÃ³ri itapá»¹ime, ajÃ©pa. NderejuhÃºi KachÃ­kepe, ajÃ©paâ€.\\n\\nUpe karai ombohovÃ¡i chupe: â€œAÃ±etehÃ¡pe, ndajuhÃºi hese. Ahareiete, chakeko mombyry korÃ³cho. Ha ndÃ©piko mbaâ€™Ã©icha reikuaa KachÃ­ke ndaiporiha itapá»¹imeâ€, ha Ã±ande ypykue ombohovaijey kÃ³icha: â€œHa chÃ©ngo hÃ­na KachÃ­ke...â€\\n\\nUpÃ©va ohendÃºvo, pe karai oporandu chupe: â€œHa mbaâ€™Ã©re piko ajeâ€™i neremombeâ€™Ãºi kuri chÃ©veâ€ ha KachÃ­ke ombohovÃ¡i chupe: â€œHa ndÃ©ngo reporandÃºkuri chÃ©ve KachÃ­ke rÃ³gapa moÃ¶ opytaâ€.\\n\\nDIPLOMA\\n(Omombeâ€™Ãºva: VÃ­ctor RomÃ¡n InsfrÃ¡n MartÃ­nez - ParaguaÃ½pe)\\nPeteÃ¯ kariaâ€™y oporandu peteÃ¯ karaÃ­pe: â€œMbaâ€™Ã©ichapiko hÃ©ra ne remiarirÃ¶â€.\\nKarai heâ€™i chupe: â€œHÃ©ra Diplomaâ€.\\nâ€œHa... mbaâ€™Ã©repiko hÃ©ra Diplomaâ€, oporandujey pe kariaâ€™ymi.\\nâ€œHa... che rajÃ½ngo oho ParaguaÃ½pe ha oÃ±emoarandu UV Internacional-pe. UpÃ©pe oikuaa avei peteÃ¯ kariaâ€™Ã½pe pyaâ€™evoi oikÃ³va hendive. Are rire che rajy ojevyjey ore rÃ³gape, peteÃ¯ mitÃ¤â€™i ijyva ari, ha ogÌƒuahÃ«vo Ã³gape, heâ€™Ã­kuri chÃ©ve: naâ€™Ã¡pe, kÃ³va haâ€™e che diplomaâ€.\\n\\nESCARABAJO\\n(Omombeâ€™Ãºva: Serafina HaidÃ©e Villalba â€“ San Pedro del Parana)\\nMokÃ¶i guaâ€™i omonda peteÃ¯ Volkswagen Escarabajo ha nimboraâ€™e haâ€™ekuÃ©ra ndoikuaÃ¡i pÃ©va oguerekoha i-motor hapykuÃ©pe.\\n\\t\\nOjupÃ­vo, peteÃ¯va omboguatÃ¡makatu pe escarabajoâ€™i ha upÃ©i opytasapyâ€™a chuguikuÃ©ra tapÃ©pe ha pe omboguatÃ¡va heâ€™i hapichÃ¡pe: â€œPyaâ€™e ehecha Ã±andÃ©ve mbaâ€™Ã©pa ojehu motor-peâ€ ha pÃ©va -ndoikuaÃ¡gui i-motor oÃ¯ha hapykue gotyo, oheka henonde gotyo- omaâ€™Ã«vo heâ€™i: â€œÂ¡Hoâ€™Ã¡ngoraâ€™e i-motor!â€ ha upÃ©marÃ¶ ohejarei hikuÃ¡i pe Escarabajo ha ohÃ³nte hikuÃ¡i yvy rupi.\\n\\nYVYRARO\\n(Omombeâ€™Ãºva: Luciano MÃ©ndez Lovera â€“ San Roque GonzÃ¡lez)\\nPeteÃ¯ karai heâ€™i ambuÃ©pe: â€œNdohasÃ¡ipa gueterei kamiÃ¶ Yvyraroâ€. \\nPe karai ombohovÃ¡i chupe: â€œHeta kamiÃ¶ma ohasa... Ã¡gÌƒa pe mbaâ€™e ndaikuaaporÃ¤ivaningo mbaâ€™e yvyraguÃ¡paâ€.\\n\\nSANDIA\\n(Omombeâ€™Ãºva: Mirtha Alegre de GonzÃ¡lez â€“ Coronel Bogado; \\nha Pablino GÃ³mez Vera â€“ San Lorenzo)\\nPeteÃ¯ kuÃ±ataÃ¯ ohasa KachÃ­ke rÃ³ga renonde rupi, sandia ijyva Ã¡ri. OhasÃ¡vo KachÃ­ke renonde rupi, kÃ³va heâ€™i kuÃ±ataÃ¯me: â€œAikosetÃ©pa nde sandiÃ¡rÃ¶â€.\\n\\nKuÃ±ataÃ¯ osÃ« oporandu chupe: â€œKachÃ­ke, mbaâ€™Ã©reiko ere chÃ©ve pÃ©ichaâ€.\\nKachÃ­ke, maÃ±a tieâ€™á»¹re, osÃ« ombohovaijey kuÃ±akataÃ¯me, kÃ³icha: â€œcheâ€™u hagÌƒua che raâ€™á»¹i entero-reâ€.\\n\\nDOS MANGOS\\n(Omombeâ€™Ãºva: RubÃ©n Rolandi â€“ Mariano Roque Alonso)\\nKachÃ­ke opiropea mokÃ¶i kuÃ±ataÃ¯me ha heâ€™i chupekuÃ©ra: â€œComo quisiera ser esos dos mangos peâ€™Ãºvaâ€.\\nPeteÃ¯va kuÃ±ataÃ¯ osÃ« oporandu KachÃ­kepe: â€œÂ¿Para quÃ©?â€.  \\nKachÃ­ke ombohovÃ¡i kÃ³icha: â€œHa porque peâ€™upa rire la che roâ€™o, peipytÃ©ta che raâ€™á»¹iâ€.\\n\\nSANACIÃ“N\\n(Omombeâ€™Ãºva: Felipe Nery Miranda â€“ Arroyos y Esteros)\\nKÃ³va oiko peteÃ¯ aty sanacion-guÃ¡pe. Heâ€™i pe Pastor omotenondÃ©va pe aty: â€œPepoko pene mbaâ€™asÃ½reâ€.\\nPeteÃ¯ opoko iÃ±akÃ¤re, ambue opoko hetymÃ¡re ha upÃ©icha ojapojoaite umi tapicha ijatÃ½va. PeichahÃ¡gui Pastor omaÃ±a hugua gotyo ha ohecha upÃ©pe peteÃ¯ tujaâ€™i opokÃ³va henondÃ©re. UpÃ©va ohechÃ¡vo Pastor osÃ« heâ€™i: â€œChÃ©ngo ajapo sanaciÃ³n, ndajapÃ³i resurrecciÃ³nâ€.\\n\\nHIELO\\n(Omombeâ€™Ãºva: Saturnina DÃ­az Molinas â€“ General ResquÃ­n)\\nKachÃ­ke ohohÃ­na tapÃ©re ha peichahÃ¡guinte oÃ±epysÃ¤nga peteÃ¯ itÃ¡re. PeteÃ¯ kuÃ±ataÃ¯ omeâ€™Ã« chupe hielo ha KachÃ­ke omoÃ¯ hyÃ©re.\\nKuÃ±ataÃ¯ oporandu KachÃ­kepe mbaâ€™Ã©repa omoÃ¯ hyÃ©re, ha KachÃ­ke ombohovÃ¡i chupe: â€œAmbogue hagÌƒua chepyâ€™araku, porque chepyâ€™arakÃºguinte aÃ±epysÃ¤ngaâ€.\\n\\nDE FONDO\\n(Omombeâ€™Ãºva: Miguel DomÃ­nguez Arbe â€“ Villa Hayes)\\nPeteÃ¯ karai ojejuhÃºvo KachÃ­ke ndive, oporandu chupe: â€œKachÃ­ke, mboÃ½piko oguereko nde yvy, de fondoâ€.\\nKachÃ­ke ombohovÃ¡i chupe: â€œNdaikuaÃ¡iâ€. UpÃ©marÃ¶ pe karai heâ€™ijey chupe: â€œMbaâ€™Ã©ichapiko ndereikuaamoâ€™Ã¤iâ€.\\nKachÃ­ke ombohovaijey chupe: â€œHa mbaâ€™Ã©ichapiko aikuaÃ¡ta... ko neâ€™Ã¯rÃ¤va ajoâ€™oâ€.\\n\\nMBARAKAJA HA VAKA\\n(Omombeâ€™Ãºva: Lorenzo Quintana EspÃ­nola â€“ Juan de Mena)\\nMbarakaja oguapyhÃ­na yvyra akÃ¤ Ã¡ri ha vaka opuka oÃºvo hendÃ¡pe. Mbarakaja oporandu chupe mbaâ€™Ã©repa opuka ha vaka heâ€™i chupe: â€œApukÃ¡nteko nderehe nemichÃ¯ ha ndevigotepÃ¡maâ€, ha ojere oho.\\nUpeichahÃ¡guinte ohendu opuka mbarakaja ha vaka ojerevoi omaÃ±a hese ha oporandu chupe mbaâ€™Ã©repa opuka. UpÃ©pe mbarakaja heâ€™i chupe: â€œNdÃ©katu negÌƒuaigÌƒuÃ­ma ha neretÃ¯ri reiko hagÌƒua, pÃ©icha, nde titi okÃ¡peâ€.\\n\\nKAVAJU PYTÃ„\\n(Omombeâ€™Ãºva: Rosa Jacilda Cardozo de Duarte â€“ Ciudad del Este)\\nPeteÃ¯ karai heâ€™i KachÃ­kepe: â€œNderehechÃ¡ipa peteÃ¯ kavaju chembaâ€™Ã©vaâ€. KachÃ­ke ombohovÃ¡i chupe: â€œNdahaâ€™Ã©ipiko peteÃ¯ kavaju pytÃ¤, isÃ¤mbukÃºvaâ€.\\nOhendÃºvo upÃ©va karaimi ovyâ€™Ã¡voi ha heâ€™i: â€œHÃ©Ã«. Haâ€™etÃ©maâ€, ha KachÃ­ke heâ€™ijey chupe kÃ³icha: â€œUpÃ©va haâ€™Ã©ramo... ndahechÃ¡iâ€.\\n\\nEJERE\\n(Omombeâ€™Ãºva: Serafina HaidÃ©e Villalba â€“ San Pedro del Parana)\\nKachÃ­ke ojahÃºhina, ynoâ€™Ã¶me, tape ykÃ©pe. Upe jave ohasa upÃ©rupi peteÃ¯ kuÃ±akarai osapukÃ¡iva chupe: â€œKachÃ­ke, ejereâ€.\\nKachÃ­ke ombohovÃ¡i chupe: â€œE, rehechÃ¡ma che renonde ha Ã¡gÌƒa rehechasÃ©ma che revi aveiâ€.\\n\\nHUMO ASADO\\n(Omombeâ€™Ãºva: Porfiria Orrego Invernizzi â€“ San Lorenzo)\\nKachÃ­ke itavÃ½vaicha, ikÃ¼ okÃ¡pe, omuÃ±a peteÃ¯ tren ha heâ€™i ohÃ³vo: â€œChÃºku chÃºku, chÃºku chÃºku, chÃºku chÃºku, donde hay humo hay asadoâ€\\n\\nNEâ€™ÃRÃ„ ORAMBOSA\\n(Omombeâ€™Ãºva: Catalino Gilberto Recalde - Villeta)\\nKachÃ­ke ohohÃ­na ha peteÃ¯ karai oporandu chupe: â€œMbaâ€™Ã©iko rejaporeÃ­na, KachÃ­keâ€. KÃ³va ombohovÃ¡i karaÃ­pe: â€œOkaÃ±y che guÃ©iâ€. Pe karai oporandujey chupe: â€œNdahaâ€™Ã©i piko peteÃ¯ hÃ¼vaâ€.\\n\\nâ€œPÃ©va haâ€™eâ€, heâ€™i KachÃ­ke vyâ€™apÃ³pe ha ombojoapy: â€œMoÃ¶pa oimehÃ­naâ€.\\n\\nKarai heâ€™i chupe kÃ³icha: â€œOime amo kaâ€™aguy ykÃ©pe, okarÃºhinaâ€.\\n\\nOhendÃºvo upÃ©va, KachÃ­ke osÃ« heâ€™i karaimÃ­me: â€œPÃ©va ndahaâ€™Ã©i chembaâ€™e porque chembaâ€™e neâ€™Ã¯rÃ¤ gueterei orambosaâ€.\\n\\nYVY RUPI\\n(Omombeâ€™Ãºva: Ramona Ayala ColmÃ¡n - Kapiata)\\nPeteÃ¯ Ã¡ra, Villarrica-pe Guaâ€™i ojupi mbaâ€™yruguatÃ¡pe ha ohepymeâ€™Ã«pa rire i-pasaje mboguatahÃ¡rape, oguejyjey mbaâ€™yruguatÃ¡gui.\\nPukavÃ½pe, oguata ogÌƒuahÃ« meve ParaguaÃ½pe -yvy rupi- ha heâ€™i ijupe ouâ€™ajahÃ­na: â€œAmbotavyete vera mbaâ€™yru mboguatahÃ¡rape. Haâ€™e oimeâ€™arÃ¤ oimoâ€™Ã¤ ajutaha imbaâ€™yruguatÃ¡peâ€.\\n\\nMILANESA\\n(Omombeâ€™Ãºva: AbdÃ³n Galeano BenÃ­tez - Kapiata)\\nLa profesora pregunta: â€œMbaâ€™Ã©pa pekarÃºkuri pende rÃ³gapeâ€.\\n\\t\\nLos mitÃ¤â€™i gritan: â€œÂ¡Milanesa!â€, menos Kaloâ€™i que dice: â€œCocidoâ€. Al escucharlo la maestra, sorprendida, le dice: â€œAnichÃ©ne. Mbaâ€™Ã©ichapiko rekarÃºta kojÃ³iâ€.\\n\\t\\nKaloâ€™i insiste: â€œOrÃ©ngo Ã³gape roarambosa, rokaru ha ro-cenÃ¡ kojÃ³intevoiâ€. Todos se burlan de Ã©l. Incluso, en el recreo sus compaÃ±eritos le ponen de marcante â€œkojÃ³iâ€. \\n\\t\\nLuego de salir de la escuela, camina hasta su casa, donde al llegar -con voz enojada- le dice al papÃ¡: â€œChe ndahamoâ€™Ã¤vÃ©ima mboâ€™ehaÃ³peâ€ y le cuenta al papÃ¡ todo lo que le ocurriÃ³ en la escuela.\\n\\t\\nEl papÃ¡ le dice: â€œAjÃ©pa nde tavy, che raâ€™y. Umi ne irÃ¼ niko ijapu. Mbaâ€™e milanesa katu piko hoâ€™Ãºta. Haâ€™ekuÃ©ra niko heâ€™Ã­nte hoâ€™uha milanesa. Nde niko reikuaa porÃ¤ Ã±andeichaitÃ©nte haâ€™ekuÃ©ra kojÃ³inte avei hoâ€™uha, Ã¡ra ha Ã¡raâ€. \\nEl papÃ¡ palmotea y anima a su hijo diciÃ©ndole: â€œKoâ€™Ã«rÃ¶ ahÃ¡ta aÃ±eâ€™Ã« ne mboâ€™ehÃ¡ra ndive. AjerurÃ©ta chupe oporandujey hagÌƒua peÃ«me mbaâ€™Ã©pa pekaru, ha Ã¡gÌƒa oporandÃºvo,  nde erÃ©ta avei reâ€™uha milanesaâ€.\\n\\t\\nAl otro dÃ­a, tal cual le dijo a Kaloâ€™i, el papÃ¡ fue y hablÃ³ con la maestra. En fin, los alumnos entraron a la clase y luego la profesora les volviÃ³ a preguntar: â€œMbaâ€™Ã©pa pekaru kuri pende rÃ³gapeâ€. A su turno Kaloâ€™i dice tambiÃ©n: â€œÂ¡Milanesa!â€. Sobre la marcha la maestra le pregunta a Kaloâ€™i: â€œHa... mboÃ½piko reâ€™uâ€.\\n\\t\\nY Kaloâ€™i, inocentemente, responde: â€œDos jarro, prosesoraâ€.\\n\\nKURE TATAKUÃPE\\n(Omombeâ€™Ãºva: Horacio Abdala â€“ ParaguaÃ½pe)\\nKachÃ­ke heâ€™i LeÃºpe: â€œNdÃ©pa reâ€™Ãºma kure tatakuÃ¡peâ€ ha Leu ombohovÃ¡i: â€œHÃ©Ã«, haâ€™ujepÃ©maâ€.\\nKachÃ­ke heâ€™ijey chupe: â€œHa mbaâ€™Ã©icha rupi nerekÃ¡i reime aja pe tatakuÃ¡peâ€.\\n\\nEN LA ESCUELA\\n(Omombeâ€™Ãºva: Santiago Flores Torres - ParaguaÃ½pe)\\nUn niÃ±o campesino, conocedor de la vida en las estancias y de las costumbres de los animales de los tambos y granjas; se muda a la ciudad y allÃ­ asiste a la escuela.\\n\\nUn dÃ­a la maestra les plantea un problema: â€œNiÃ±os, dÃ­ganme quÃ© pasa si de un corral donde hay viente ovejas, se escapan quinceâ€. Transcurre un tiempo y nadie responde.\\n\\nComo nadie responde, ella les dice: â€œLa respuesta es sencilla... en el corral quedan cinco ovejasâ€, y mirando al niÃ±o campesino le consulta: â€œÂ¿Verdad, Chive?â€.\\n\\nEl niÃ±o le responde: â€œRejavy mboâ€™ehÃ¡raâ€. Sorprendida por la respuesta, la maestra le dice: â€œMbaâ€™Ã©rÃ£pa ere ajavyhaâ€.\\nEl niÃ±o campesino le replica: â€œNdaipÃ³ri ovecha tavy, Mboâ€™ehÃ¡ra. OÃ¯ramo veinte, oÃ¯haguÃ©icha osÃ«mbaitÃ©ta okÃ¡pe. Arakaâ€™e guaâ€™u cinco opytÃ¡ta ndÃ©ve kora ryepÃ½pe\".\\n\\nAGUEREKO\\n(Omombeâ€™Ãºva: Paublino Carlos Ferreira QuiÃ±Ã³nez â€“ Fndo. de la Mora)\\nMbohapy guaâ€™i, ojojuhu hikuÃ¡i tupaÃ³pe. Haâ€˜ekuÃ©ra oÃ±omongeta kyreâ€™á»¹ kÃ³icha.\\nPe itujavÃ©va osÃ« heâ€™i: â€œChe areko peteÃ¯ ovecha heâ€™Ã­va: mbeee mbeeeâ€.\\nPe guaâ€™i mbytegua katu, ojerovu ha heâ€™i: â€œChÃ© areko peteÃ¯ ryguasu heâ€™Ã­va: kaka-karaâ€™aâ€.\\nPe guaâ€™i pahaguÃ©va oikovaâ€™ekue EspaÃ±a-pe ha ikatellÃ¡no kate asÃ½pe, osÃ« heâ€™i: â€œYo tengo un jÃ¡rro que dice â€œKaâ€™aâ€.\\n\\nCAÃ‘A\\n(Omombeâ€™Ãºva: Anthony Enciso - San Lorenzo)\\nPeteÃ® oka\\'Ãºva ogÌƒuahÃª bar-pe ha oporandu mozo-pe: â€œÂ¡Mozo!, eguereko piko caÃ±aâ€.\\nâ€œAguerekoâ€, he\\'i la mozo.\\n\\nUpÃ©i oka\\'uva he\\'i: â€œUpÃ©icharÃ¶ emboty nde bar, egueru la nde caÃ±a ha... jaha ja-pescÃ¡â€.\\n\\nMAYOR AHÃNCO\\n(Omombeâ€™Ãºva: RubÃ©n Rolandi â€“ Mariano Roque Alonso)\\nA la madrugada, en el cuartel, aÃºn en la oscuridad, la tropa inicia sus actividades del dÃ­a. Al frente, se encuentra el Coronel quien a voz en cuello, le asigna a cada soldadito la labor que le tocarÃ¡ en el dÃ­a. AsÃ­, manda lo siguiente: â€œÂ¡Mereles ha nde avei Aquinoâ€™i!, pemopotÃ¯ porÃ¤ta chÃ©ve koty oÃ¯va guive... ha pejapÃ³ta chÃ©ve con el mayor ahÃ­nco. Â¡HesakÃ¤porÃ¤pa peÃ«me!â€.\\nOhendÃºvo upÃ©va Aquinoâ€™i osÃ« heâ€™i: â€Che ruvicha, peteÃ¯ mbaâ€™Ã©nte haâ€™ese ndÃ©ve, pe mayor ahÃ­nco niko ndahaâ€™Ã©i Ã±ane unidad-guaâ€.\\n\\nTRAVESTI\\n(Omombeâ€™Ãºva: Cecilio RamÃ³n Coronel GÃ³mez â€“ Kaâ€™aguasu)\\nUn campesinito algo bruto viajaba en su automÃ³vil a ParaguaÃ½pe y al llegar a la Curva de la Muerte viÃ³ parada a una persona. Le invitÃ³ a subir a su auto y la persona le dijo: â€œSoy travestiâ€.\\nEl campesinito le contestÃ³: â€œChe naporandÃºi ndÃ©ve nde apellÃ­do-re. EjupÃ­katu jahaâ€\\n\\nPYHAREKUE\\n(Omombeâ€™Ãºva: AbdÃ³n Galeano BenÃ­tez - Kapiata)\\nUn ruso, un yanki  y el paraguayito juegan â€œquien es el mÃ¡s guapo y el que mÃ¡s lejos puede llegarâ€.\\nEl ruso empieza y dice: â€œYo con un cohete, voy y vuelvo, en un dÃ­a, a la lunaâ€. Todos festejan, aplauden y gritan â€œÂ¡grande!â€, â€œÂ¡idolo!â€.\\n\\nA su turno el yanki replica: â€œEso no es nada. Yo puedo ir a Jupiter y vuelvo en dos dÃ­asâ€. Todos festejan, aplauden y gritan â€œÂ¡grande!â€, â€œÂ¡idolo!â€.\\n\\t\\nEl paraguayito les dice: â€œPeÃ« pejÃ©va niko vyrorei. ChÃ©ngo ajapota pe tuichavÃ©va, pe ijojahaâ€™á»¹va... ahÃ¡ta ajere pe kuarahÃ½re ha ajujey pya\\'e porÃ¤\".\\n\\t\\nTodos quedan sorprendidos, anonadados, hasta que reaccionan y le dicen al paraguayito: â€œEso es imposible. Nadie puede hacer eso. CientÃ­ficamente es improbable...â€\\n\\t\\nEl paraguayito, siempre rovaâ€™Ã¤ta, les dice: â€œAjÃ©pa pendetavy peÃ« gringo. ChÃ©ngo ndahamoâ€™Ã¤i chupe arakue, chÃ©ngo ahÃ¡ta chupe pyharekueâ€.\\n\\nMARCA\\n(Omombeâ€™Ãºva: RubÃ©n Rolandi â€“ Mariano Roque Alonso)\\nKachÃ­ke oike peteÃ¯ bar-pe. Ou la mozo oporandu chupe â€œMbaâ€™e marca de cerveza-pa reipotaâ€.\\nKachÃ­ke ombohovÃ¡i: â€œOimehaichaguÃ¡nte egueru chÃ©ve, chÃ©ngo nda-lee-kuaaivoiâ€.ðŸ˜‚ðŸ˜‚ðŸ˜‚\\n\\nKURE Ã‘EHA\\'Ãƒ\\n(Omombeâ€™Ãºva: wilfrido cabrera diaz â€“ hetave guive) peteÄ© jeÃ½pe oÃ±embyaty kachÃ­ckekuÃ©ra oha\\'Ã£ partido ha peteÄ© tiro librepe opyvoitajave kachÃ­ke vakapipopÃ³re ohasa peteÄ© kure ka\\'aguy ha opyvoi hese ha upÃ©i oho hospitalpe. UpÃ©i hi\\'irÅ©nguÃ©ra oho hendÃ¡pe omaÃ±a kachÃ­kere hikuÃ¡i ha kachÃ­ke hetyma opáº½mbaite, opukavy hÃ­na, ha hikuÃ¡i oporandu chupe: Mba\\'Ã©re piko repuka kachÃ­ke - Igrasia ko chÃ©ve, aikuaase mba\\'Ã©icha\\'anga opyta pe oha\\'Ã£ iÃ±akÃ£pe pe tiro libre\\n\\nFuentes \\nPor David Galeano Olivera (ATENEO DE LENGUA Y CULTURA GUARANI - PARAGUAY)\\n\\nAvaÃ±e\\'áº½',\n",
              "  'question': \"Mba'Ã©pa he'ise KachÃ­ke oikÃ©vo tren-pe?\",\n",
              "  'answers': {'answer_start': [24857],\n",
              "   'text': ['ChÃºku chÃºku, chÃºku chÃºku, chÃºku chÃºku, donde hay humo hay asado']},\n",
              "  'url': 'https://gn.wikipedia.org/wiki/Pukar%C3%A3'})"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbbtqnCvtEw8"
      },
      "source": [
        "There are several important fields here:\n",
        "\n",
        "- `answers`: the starting location of the answer token and the answer text.\n",
        "- `context`: background information from which the model needs to extract the answer.\n",
        "- `question`: the question a model should answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exr96oZLtEw9"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "cellView": "form",
        "hide_input": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "NcPxeq9utEw9",
        "outputId": "e5b0abc2-1c0a-41de-8715-95fba921540c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/qgaM0weJHpA?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "#@title\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/qgaM0weJHpA?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xCj8k4stEw9"
      },
      "source": [
        "The next step is to load a DistilBERT tokenizer to process the `question` and `context` fields:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "WqSsekujtEw9"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/xlm-v-base\")\n",
        "#\"mmaguero/gn-bert-tiny-cased\")\n",
        "#\"distilbert/distilbert-base-uncased\")\n",
        "#\"mmaguero/multilingual-bert-gn-base-cased\") #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kamF8BUxtEw9"
      },
      "source": [
        "There are a few preprocessing steps particular to question answering tasks you should be aware of:\n",
        "\n",
        "1. Some examples in a dataset may have a very long `context` that exceeds the maximum input length of the model. To deal with longer sequences, truncate only the `context` by setting `truncation=\"only_second\"`.\n",
        "2. Next, map the start and end positions of the answer to the original `context` by setting\n",
        "   `return_offset_mapping=True`.\n",
        "3. With the mapping in hand, now you can find the start and end tokens of the answer. Use the [sequence_ids](https://huggingface.co/docs/tokenizers/main/en/api/encoding#tokenizers.Encoding.sequence_ids) method to\n",
        "   find which part of the offset corresponds to the `question` and which corresponds to the `context`.\n",
        "\n",
        "Here is how you can create a function to truncate and map the start and end tokens of the `answer` to the `context`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "xJH14Og8tEw9"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=384,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    answers = examples[\"answers\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        answer = answers[i]\n",
        "        start_char = answer[\"answer_start\"][0]\n",
        "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label it (0, 0)\n",
        "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4FxWjGOtEw9"
      },
      "source": [
        "To apply the preprocessing function over the entire dataset, use ðŸ¤— Datasets [map](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map) function. You can speed up the `map` function by setting `batched=True` to process multiple elements of the dataset at once. Remove any columns you don't need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329,
          "referenced_widgets": [
            "a9f02dfbc6ba4c3abc2cda66b069a4f8",
            "9a4490d2f037446980280a8efcec3828",
            "4c162c9ba6c64b0884a156b22e206a2c",
            "71698bdfcfea4058bb3e2c1af42edddf",
            "6c1f59d7a34b4dc881960d036f3ba73a",
            "6eb1d14d39024505ac7d4260e64f34a9",
            "9da4433607b9468faeaa46830e4bc3c9",
            "ad8991fc47144223ab3142509354c499",
            "afe89a0f2a2d41679b96a5cb147a1f46",
            "643a0c0f34ae4660aae79e4546f9d82c",
            "855e24c282d74f54a77effa1f996c854"
          ]
        },
        "id": "VEUK18AztEw-",
        "outputId": "e4954fc9-307c-439f-93f6-b17af978e956"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/501 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9f02dfbc6ba4c3abc2cda66b069a4f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized dataset structure:\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
            "        num_rows: 4220\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
            "        num_rows: 282\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
            "        num_rows: 501\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "tokenized_squad = squad_final.map(preprocess_function, batched=True, remove_columns=squad_final[\"train\"].column_names)\n",
        "print(\"Tokenized dataset structure:\")\n",
        "print(tokenized_squad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3wDJ_p4tEw-"
      },
      "source": [
        "Now create a batch of examples using [DefaultDataCollator](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DefaultDataCollator). Unlike other data collators in ðŸ¤— Transformers, the [DefaultDataCollator](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DefaultDataCollator) does not apply any additional preprocessing such as padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "2LSzoScxtEw-"
      },
      "outputs": [],
      "source": [
        "#from transformers import DefaultDataCollator\n",
        "\n",
        "#data_collator = DefaultDataCollator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSn5hPkUtEw_"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T25J8Gp5tEw_"
      },
      "source": [
        "Evaluation for question answering requires a significant amount of postprocessing. To avoid taking up too much of your time, this guide skips the evaluation step. The [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) still calculates the evaluation loss during training so you're not completely in the dark about your model's performance.\n",
        "\n",
        "If you have more time and you're interested in how to evaluate your model for question answering, take a look at the [Question answering](https://huggingface.co/course/chapter7/7?fw=pt#post-processing) chapter from the ðŸ¤— Hugging Face Course!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try this [guide](https://huggingface.co/learn/llm-course/chapter7/7?fw=pt#post-processing)..."
      ],
      "metadata": {
        "id": "39qoQk3yBd1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "metric = evaluate.load(\"squad\")\n",
        "n_best = 20\n",
        "max_answer_length = 30\n",
        "\n",
        "def compute_metrics(start_logits, end_logits, features, examples):\n",
        "    example_to_features = collections.defaultdict(list)\n",
        "    for idx, feature in enumerate(features):\n",
        "        example_to_features[feature[\"example_id\"]].append(idx)\n",
        "\n",
        "    predicted_answers = []\n",
        "    for example in tqdm(examples):\n",
        "        example_id = example[\"id\"]\n",
        "        context = example[\"context\"]\n",
        "        answers = []\n",
        "\n",
        "        # Loop through all features associated with that example\n",
        "        for feature_index in example_to_features[example_id]:\n",
        "            start_logit = start_logits[feature_index]\n",
        "            end_logit = end_logits[feature_index]\n",
        "            offsets = features[feature_index][\"offset_mapping\"]\n",
        "\n",
        "            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
        "            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
        "            for start_index in start_indexes:\n",
        "                for end_index in end_indexes:\n",
        "                    # Skip answers that are not fully in the context\n",
        "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
        "                        continue\n",
        "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
        "                    if (\n",
        "                        end_index < start_index\n",
        "                        or end_index - start_index + 1 > max_answer_length\n",
        "                    ):\n",
        "                        continue\n",
        "\n",
        "                    answer = {\n",
        "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
        "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
        "                    }\n",
        "                    answers.append(answer)\n",
        "\n",
        "        # Select the answer with the best score\n",
        "        if len(answers) > 0:\n",
        "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
        "            predicted_answers.append(\n",
        "                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n",
        "            )\n",
        "        else:\n",
        "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
        "\n",
        "    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n",
        "    return metric.compute(predictions=predicted_answers, references=theoretical_answers)"
      ],
      "metadata": {
        "id": "agMK2RdxwSA7"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 384\n",
        "stride = 128\n",
        "\n",
        "def preprocess_validation_examples(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=max_length,\n",
        "        truncation=\"only_second\",\n",
        "        stride=stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "    example_ids = []\n",
        "\n",
        "    for i in range(len(inputs[\"input_ids\"])):\n",
        "        sample_idx = sample_map[i]\n",
        "        example_ids.append(examples[\"id\"][sample_idx])\n",
        "\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "        offset = inputs[\"offset_mapping\"][i]\n",
        "        inputs[\"offset_mapping\"][i] = [\n",
        "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
        "        ]\n",
        "\n",
        "    inputs[\"example_id\"] = example_ids\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "RRcvPCfrCi8U"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataset = squad_final[\"validation\"].map(\n",
        "    preprocess_validation_examples,\n",
        "    batched=True,\n",
        "    remove_columns=squad_final[\"validation\"].column_names,\n",
        ")\n",
        "len(squad_final[\"validation\"]), len(validation_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S274W33FClx4",
        "outputId": "3c547204-21e7-4263-f7d6-4d0026c591cf"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(282, 1595)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = squad_final[\"test\"].map(\n",
        "    preprocess_validation_examples,\n",
        "    batched=True,\n",
        "    remove_columns=squad_final[\"test\"].column_names,\n",
        ")\n",
        "len(squad_final[\"test\"]), len(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ilnk8qIFgjA",
        "outputId": "adb439d7-65c4-4f53-d867-7081c7fd2ec5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(501, 2540)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_training_examples(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=max_length,\n",
        "        truncation=\"only_second\",\n",
        "        stride=stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "    answers = examples[\"answers\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        sample_idx = sample_map[i]\n",
        "        answer = answers[sample_idx]\n",
        "        start_char = answer[\"answer_start\"][0]\n",
        "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label is (0, 0)\n",
        "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "mXikwHKWC6d7"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = squad_final[\"train\"].map(\n",
        "    preprocess_training_examples,\n",
        "    batched=True,\n",
        "    remove_columns=squad_final[\"train\"].column_names,\n",
        ")\n",
        "len(squad_final[\"train\"]), len(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "2bfe501f109e435e91b5dfb51cf8b07d",
            "035453d7b7764332a31285f6fe257159",
            "eadc47b5ec0744689ea984ccac11455d",
            "d991eeb0d867409098fbebfd84e6d342",
            "4d9e8f44218a48989c10a631bb4974df",
            "7b9bc61b318f4a58b09ee8ee975dec46",
            "d0bbcde7ec1f49e8be0f2e41a23c2693",
            "bec5431f5e354e95982e078927300370",
            "b36840c118d64a0aaaa3939fb4c459ff",
            "66521c1336e8456985f165c5181f5b19",
            "03254bfd93b7497aa9333eb70a794818"
          ]
        },
        "id": "iDaZRp1rDQ06",
        "outputId": "b0c16814-c66b-4ffe-8822-0698376a38b4"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4220 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bfe501f109e435e91b5dfb51cf8b07d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4220, 20995)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlQckThMtEw-"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkR8J4mptEw-"
      },
      "source": [
        "<Tip>\n",
        "\n",
        "If you aren't familiar with finetuning a model with the [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer), take a look at the basic tutorial [here](https://huggingface.co/docs/transformers/main/en/tasks/../training#train-with-pytorch-trainer)!\n",
        "\n",
        "</Tip>\n",
        "\n",
        "You're ready to start training your model now! Load DistilBERT with [AutoModelForQuestionAnswering](https://huggingface.co/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForQuestionAnswering):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbX18prltEw-",
        "outputId": "b690dc70-ddf0-4c15-ef4e-eb35e7a1c265"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForQuestionAnswering were not initialized from the model checkpoint at facebook/xlm-v-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"facebook/xlm-v-base\")\n",
        "#\"mmaguero/gn-bert-tiny-cased\")\n",
        "#\"mmaguero/multilingual-bert-gn-base-cased\")\n",
        "#\"distilbert/distilbert-base-uncased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiodO4j2tEw-"
      },
      "source": [
        "At this point, only three steps remain:\n",
        "\n",
        "1. Define your training hyperparameters in [TrainingArguments](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments). The only required parameter is `output_dir` which specifies where to save your model. You'll push this model to the Hub by setting `push_to_hub=True` (you need to be signed in to Hugging Face to upload your model).\n",
        "2. Pass the training arguments to [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) along with the model, dataset, tokenizer, and data collator.\n",
        "3. Call [train()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train) to finetune your model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "def cleanup():\n",
        "    \"\"\"Try to free GPU memory\"\"\"\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "3_QjLpREQv93"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
        "cleanup()"
      ],
      "metadata": {
        "id": "zfO_0-QkQ6Ue"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIFW8cL5tEw-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "cdb7efce-ab04-4992-e32e-31d38ccfc162"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2001' max='6565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2001/6565 36:48 < 1:24:03, 0.90 it/s, Epoch 1.52/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.603500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.456600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.199200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"multi-wiki-qa-gn-xlm-v-base\",\n",
        "    #output_dir=\"multi-wiki-qa-gn-bert-tiny-cased\",\n",
        "    #output_dir=\"multi-wiki-qa-multilingual-bert-gn-base-cased\",\n",
        "    eval_strategy=\"no\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    #metric_for_best_model=\"combined\",\n",
        "    push_to_hub=False,\n",
        "    fp16=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,#tokenized_squad[\"train\"],\n",
        "    eval_dataset=validation_dataset,#tokenized_squad[\"validation\"],\n",
        "    processing_class=tokenizer,\n",
        "    #data_collator=data_collator,\n",
        "    #compute_metrics=compute_metrics,\n",
        "\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, _, _ = trainer.predict(validation_dataset)\n",
        "start_logits, end_logits = predictions\n",
        "compute_metrics(start_logits, end_logits, validation_dataset, squad_final[\"validation\"])"
      ],
      "metadata": {
        "id": "5ZFeAP0HOuQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, _, _ = trainer.predict(test_dataset)\n",
        "start_logits, end_logits = predictions\n",
        "compute_metrics(start_logits, end_logits, test_dataset, squad_final[\"test\"])"
      ],
      "metadata": {
        "id": "Y-qXMMgdPJLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "zpTk_EZv0oJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6tXKNdMtEw-"
      },
      "source": [
        "Once training is completed, share your model to the Hub with the [push_to_hub()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.push_to_hub) method so everyone can use your model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5t4pG-eLtEw-"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7Gzu5E4tEw_"
      },
      "source": [
        "<Tip>\n",
        "\n",
        "For a more in-depth example of how to finetune a model for question answering, take a look at the corresponding\n",
        "[PyTorch notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering.ipynb).\n",
        "\n",
        "</Tip>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyxMRs8atEw_"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzja8d4itEw_"
      },
      "source": [
        "Great, now that you've finetuned a model, you can use it for inference!\n",
        "\n",
        "Come up with a question and some context you'd like the model to predict:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CSlo0ogtEw_"
      },
      "outputs": [],
      "source": [
        "question = \"Mbaâ€™e Ã¡rapepa heÃ±Ã³ikuri JosÃ© Carlos Cabrera?\"\n",
        "context = \"\"\"JosÃ© Carlos Cabrera (Sapucai, 1 jasypokÃµi ary 1989 -pe) ha'e peteÄ© artista paraguayo concierto guitarra clÃ¡sica rehegua.\n",
        "\n",
        "Mba'apokuaa teÃ©va\n",
        "Ary 2010 guive oiko Buenos Aires, Argentina-pe, upÃ©pe oÃ±emotenonde licenciatura de MÃºsica orekÃ³va especializaciÃ³n Guitarra-pe, oÃ±emoarandÃºvo Javier Bravo ndive Departamento de Artes Musicales y Sonido \"Carlos LÃ³pez Buchardo\" Universidad Nacional de Artes-pe.\n",
        "\n",
        "Ko'Ã£ga, ojeguereko ha'eha peteÄ©va umi omomba'eguasÃºva AgustÃ­n PÃ­o Barrios \"MangorÃ©\" purahÃ©i, ha, jepÃ©mo imitÃ£, ha'e guitarrista paraguayo omoingevÃ©va Barrios rembiapokue irrepertorio-pe.\n",
        "\n",
        "Marzo 2010 jave, ojere Europa-pe, ombovy'Ã¡vo pÃºblico-pe umi obra \"MangorÃ©\" Francia ha Holanda-pe.\n",
        "\n",
        "Ome'Ãª heta concierto Argentina-pe, umÃ­va apytÃ©pe Festival Internacional Guitarras del Mundo, 2o Encuentro Internacional Guitarra, ha Festival Internacional TSONAMI de MÃºsica ContemporÃ¡nea, orepresentÃ¡va Paraguay orekÃ³va estreno obra contemporÃ¡nea \"MangorÃ©\" compositor paraguayo NicolÃ¡s PÃ©rez GonzÃ¡lez. Avei oime kuri ParaguÃ¡i representante ramo Feria Internacional del Libro Buenos Aires 2011-pe.\n",
        "\n",
        "Ojekuaa solista invitado ramo heta orquesta ndive: Orquesta SinfÃ³nica Nacional de Argentina, Orquesta SinfÃ³nica Ciudad de AsunciÃ³n, Camerata Miranda, ha Orquesta CÃ¡mara Centro Cultural Paraguayo-Americano, upÃ©pe oestrena concierto guitarra, flauta ha orquesta \"Homage to MangorÃ©\" Maestro Luis SzarÃ¡n. Omotenonde director nacional ha internacional, ha'ehÃ¡icha Diego SÃ¡nchez Haase, CÃ©sar Manuel \"Lito\" Barrios, Miguel A. Gilardi, ha Javier Aquino Maidana, ambue apytÃ©pe.\n",
        "\n",
        "ParaguÃ¡ipe ombosakoâ€™i mokÃµi programa amplio orekÃ³va AgustÃ­n Barrios rembiapo, ojejapÃ³va opÃ¡ichagua tendÃ¡re tetÃ£ pukukue. PeteÃ®va umi concierto oiko MangorÃ© mansiÃ³n San Juan Bautista-pe, oiporÃºvo guitarra Morant ha'eva'ekue AgustÃ­n Barrios mba'e. Avei omimbi oparticipÃ¡vo 5o Festival Internacional de Guitarra \"Homage a MangorÃ©\", oÃ±emotenondÃ©va AsunciÃ³n-pe. Ome'Ã« actuaciones significativas, ha'ehÃ¡icha concierto omotenondÃ©va estreno mundial Ãºnico obra guitarra clÃ¡sica-pe guarÃ£ ilustre compositor paraguayo Carlos Lara Bareiro, 22 ary omanÃ³ha. Ohupyty peteÃ®ha jopÃ³i concurso internacional interpretaciÃ³n \"Momento Musical Opus 2009\" agosto upe arÃ½pe AsunciÃ³n, Paraguay-pe, ha oime juez ramo upe competencia-pe guarÃ£ ambue arÃ½pe. Avei ohupyty mokÃµiha jopÃ³i \"Musicampus 2007 Guitarra ClÃ¡sica Concurso\" CÃ³rdoba, Argentina-pe.\n",
        "\n",
        "Oike mundo de la mÃºsica-pe orekÃ³pe 11 ary, mÃºsica folklÃ³rica paraguaya rupive. OrekÃ³pe 14 ary, oÃ±epyrÅ© ijestudio violÃ­n rehegua, ha orekÃ³pe 15 ary, oiporavo definitivamente guitarra clÃ¡sica instrumento principal ramo. OÃ±embokatupyry iÃ±epyrÃ»hÃ¡pe umi conservatorio ojeguerohorÃ½va mbo'ehÃ¡ra paraguayo ojekuaÃ¡va ndive, omohu'Ã£vo honores orekÃ³va 18 ary orekÃ³va carrera ActuaciÃ³n de Guitarra ClÃ¡sica ha TeorÃ­a de la MÃºsica ha SolfÃ¨ge. Ojapo opÃ¡ichagua curso avanzado guitarrista herakuÃ£itÃ©va ndive, umÃ­va apytÃ©pe Pablo MÃ¡rquez, Eduardo FernÃ¡ndez, JosÃ© Antonio Escobar, Berta Rojas, ha VÃ­ctor Villadangos, ambue apytÃ©pe.\n",
        "\n",
        "...â€œRohecha hÃ­na peteÄ© talento excepcional, peteÄ© mitÃ£rusu, ademÃ¡s de italento, orekÃ³va virtudes haâ€™ehÃ¡icha humildad, seriedad, dedicaciÃ³n ha peteÄ© capacidad expresiva haâ€™Ã©va peteÄ© joya ojejuhÃºva mbovyeterei intÃ©rprete-peâ€ (Berta Rojas).\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIYNcqVStEw_"
      },
      "source": [
        "The simplest way to try out your finetuned model for inference is to use it in a [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline). Instantiate a `pipeline` for question answering with your model, and pass your text to it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIPwFuvjtEw_"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "question_answerer = pipeline(\"question-answering\",\n",
        "                             #model=\"mmaguero/multi-wiki-qa-multilingual-bert-gn-base-cased\"\n",
        "                             #model=\"mmaguero/multi-wiki-qa-gn-bert-tiny-cased\"\n",
        "                             model=\"mmaguero/multi-wiki-qa-gn-xlm-v-base\"\n",
        "                             )\n",
        "question_answerer(question=question, context=context)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Moo oiko JosÃ© Carlos Cabrera?\"\n",
        "question_answerer(question=question, context=context)"
      ],
      "metadata": {
        "id": "Jd7z6iJ0T4RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_answerer(question=question, context=context, top_k=3)"
      ],
      "metadata": {
        "id": "8egK87MkUrV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Araka'e oÃ±epyrÅ© ijestudio violÃ­n rehegua?\"\n",
        "question_answerer(question=question, context=context, top_k=5)"
      ],
      "metadata": {
        "id": "yaGSaamPGxCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fvb0mDatEw_"
      },
      "source": [
        "You can also manually replicate the results of the `pipeline` if you'd like:\n",
        "\n",
        "Tokenize the text and return PyTorch tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ml1rFdtYtExE"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    #\"mmaguero/multi-wiki-qa-gn-bert-tiny-cased\"\n",
        "    \"mmaguero/multi-wiki-qa-gn-xlm-v-base\"\n",
        "    )\n",
        "inputs = tokenizer(question, context, return_tensors=\"pt\", truncation=True, max_length=384)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYkYzEJbtExE"
      },
      "source": [
        "Pass your inputs to the model and return the `logits`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mh3ydxj-tExE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForQuestionAnswering\n",
        "\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\n",
        "    #\"mmaguero/multi-wiki-qa-gn-bert-tiny-cased\"\n",
        "    \"mmaguero/multi-wiki-qa-gn-xlm-v-base\"\n",
        "    )\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lwJYmJdtExF"
      },
      "source": [
        "Get the highest probability from the model output for the start and end positions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gV9fBefOtExF"
      },
      "outputs": [],
      "source": [
        "answer_start_index = outputs.start_logits.argmax()\n",
        "answer_end_index = outputs.end_logits.argmax()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4c7KOMvtExF"
      },
      "source": [
        "Decode the predicted tokens to get the answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlkIcixItExF"
      },
      "outputs": [],
      "source": [
        "predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
        "#tokenizer.decode(predict_answer_tokens)\n",
        "predict_answer_tokens"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "79923602ad684364b96b4f04f6df9512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12c03d01af92403c910e2a69b61e9c86"
            ],
            "layout": "IPY_MODEL_396f9d07c84244799acb36ea07277a37"
          }
        },
        "d3d9f44db6db413a97cc3a8948ffa5dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44f15dc0109448b2919faba466feca86",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_86141c3231ed4da5bc3e88e639e148d2",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "4d63bad454ca439389431cf44acf546f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_6a3925dba8344196be1eb6a2db9c86ec",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0b8baa4903de4dc0843d85e2601ade18",
            "value": ""
          }
        },
        "7d1b3193f2bc4cbbbbb6aa08aa096600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_a9d02c340b8c4716b3fe46910abbb4c3",
            "style": "IPY_MODEL_6fb345693fdc49fb9d5b4e24332a651f",
            "value": true
          }
        },
        "585a31b5282d4e129222f30b5a3b9bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_d0952fd951d04694b8bb28c44beb3ff7",
            "style": "IPY_MODEL_e52863f611a64905a54abcef0f5828ac",
            "tooltip": ""
          }
        },
        "121926a260e74f128a908588172a5bfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84baa25590a64e58bea7c18f20fbe6c3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bf52da850aa94074886ba9dbedfedcb8",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "396f9d07c84244799acb36ea07277a37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "44f15dc0109448b2919faba466feca86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86141c3231ed4da5bc3e88e639e148d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a3925dba8344196be1eb6a2db9c86ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b8baa4903de4dc0843d85e2601ade18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9d02c340b8c4716b3fe46910abbb4c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fb345693fdc49fb9d5b4e24332a651f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0952fd951d04694b8bb28c44beb3ff7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e52863f611a64905a54abcef0f5828ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "84baa25590a64e58bea7c18f20fbe6c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf52da850aa94074886ba9dbedfedcb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "309a9f6371f747baa3235a60e5877161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99e3aa9bf08b4fa5913217d1bd879bb2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_031a99086d8b4a27b3b5134a9eb4f05f",
            "value": "Connecting..."
          }
        },
        "99e3aa9bf08b4fa5913217d1bd879bb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "031a99086d8b4a27b3b5134a9eb4f05f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0051708a588b448991e4334bb96bd048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56637554015d4e9c95e3e9f72ab3f877",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4de35a30469c422aacee901f434891f3",
            "value": "Connecting..."
          }
        },
        "56637554015d4e9c95e3e9f72ab3f877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4de35a30469c422aacee901f434891f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce5a3c598b8c425daefb5c1d6bd5c13f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e12559a505884b5d90469cca9a02e303",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_509a135a07c240ab8a39875fcc76d0cb",
            "value": "Token forking not found in /root/.cache/huggingface/stored_tokens"
          }
        },
        "e12559a505884b5d90469cca9a02e303": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "509a135a07c240ab8a39875fcc76d0cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a944d227d584af8b81ffa286bd8ee21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c8b6ea9171848faa10b0efe7f98c41b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_76c2589bc33040a0a5a85ea483b9cd94",
            "value": "Connecting..."
          }
        },
        "9c8b6ea9171848faa10b0efe7f98c41b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76c2589bc33040a0a5a85ea483b9cd94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12c03d01af92403c910e2a69b61e9c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_865a289a4abb41ac99466e8dd55c46e6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3edaeb0bad2642eb837e9460266b25a0",
            "value": "Token forking not found in /root/.cache/huggingface/stored_tokens"
          }
        },
        "865a289a4abb41ac99466e8dd55c46e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3edaeb0bad2642eb837e9460266b25a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9f02dfbc6ba4c3abc2cda66b069a4f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a4490d2f037446980280a8efcec3828",
              "IPY_MODEL_4c162c9ba6c64b0884a156b22e206a2c",
              "IPY_MODEL_71698bdfcfea4058bb3e2c1af42edddf"
            ],
            "layout": "IPY_MODEL_6c1f59d7a34b4dc881960d036f3ba73a"
          }
        },
        "9a4490d2f037446980280a8efcec3828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eb1d14d39024505ac7d4260e64f34a9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9da4433607b9468faeaa46830e4bc3c9",
            "value": "Map:â€‡100%"
          }
        },
        "4c162c9ba6c64b0884a156b22e206a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad8991fc47144223ab3142509354c499",
            "max": 501,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afe89a0f2a2d41679b96a5cb147a1f46",
            "value": 501
          }
        },
        "71698bdfcfea4058bb3e2c1af42edddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_643a0c0f34ae4660aae79e4546f9d82c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_855e24c282d74f54a77effa1f996c854",
            "value": "â€‡501/501â€‡[00:02&lt;00:00,â€‡195.50â€‡examples/s]"
          }
        },
        "6c1f59d7a34b4dc881960d036f3ba73a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6eb1d14d39024505ac7d4260e64f34a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9da4433607b9468faeaa46830e4bc3c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad8991fc47144223ab3142509354c499": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afe89a0f2a2d41679b96a5cb147a1f46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "643a0c0f34ae4660aae79e4546f9d82c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "855e24c282d74f54a77effa1f996c854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bfe501f109e435e91b5dfb51cf8b07d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_035453d7b7764332a31285f6fe257159",
              "IPY_MODEL_eadc47b5ec0744689ea984ccac11455d",
              "IPY_MODEL_d991eeb0d867409098fbebfd84e6d342"
            ],
            "layout": "IPY_MODEL_4d9e8f44218a48989c10a631bb4974df"
          }
        },
        "035453d7b7764332a31285f6fe257159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b9bc61b318f4a58b09ee8ee975dec46",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d0bbcde7ec1f49e8be0f2e41a23c2693",
            "value": "Map:â€‡100%"
          }
        },
        "eadc47b5ec0744689ea984ccac11455d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bec5431f5e354e95982e078927300370",
            "max": 4220,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b36840c118d64a0aaaa3939fb4c459ff",
            "value": 4220
          }
        },
        "d991eeb0d867409098fbebfd84e6d342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66521c1336e8456985f165c5181f5b19",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_03254bfd93b7497aa9333eb70a794818",
            "value": "â€‡4220/4220â€‡[00:42&lt;00:00,â€‡94.25â€‡examples/s]"
          }
        },
        "4d9e8f44218a48989c10a631bb4974df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b9bc61b318f4a58b09ee8ee975dec46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0bbcde7ec1f49e8be0f2e41a23c2693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bec5431f5e354e95982e078927300370": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b36840c118d64a0aaaa3939fb4c459ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66521c1336e8456985f165c5181f5b19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03254bfd93b7497aa9333eb70a794818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
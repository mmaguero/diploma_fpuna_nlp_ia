{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "name": "Gemma 3N 4B Multimodal finetuning + inference",
      "toc_visible": true,
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "77a254c98dd24c8f90df9ebef6eeca48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_a77883f394b1469b85bf95e7063c801d"
          }
        },
        "17b8357518254c9dbb5ed08945d40772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c92b06575f14096ac774cc5f9d1150a",
            "placeholder": "​",
            "style": "IPY_MODEL_073ad578cc214d75977c9f776752b882",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "24f08955b08945f7933e141c2bd92d86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_e2518c0de80646a9b3c7e81e3ee73134",
            "placeholder": "​",
            "style": "IPY_MODEL_1ad76528decd4e1e90fabac6fb56dd0a",
            "value": ""
          }
        },
        "ffc37ad2eb8a4d849b4e15e1a9bc2ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_619d1c2f669e4ad9ad80f767df07997f",
            "style": "IPY_MODEL_365b7e8d60b640e4ab627604059a8bbf",
            "value": true
          }
        },
        "8a2ed8fb1df0486597d23909f63a05c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_3c366539f3d54521b8e1714f45d59c8a",
            "style": "IPY_MODEL_b9c32d09fa104ab3ad1b28aa68b5a426",
            "tooltip": ""
          }
        },
        "eef3d82b08a54c0ab714608cddc17a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c371d9d75104fafa7cb38747455d59f",
            "placeholder": "​",
            "style": "IPY_MODEL_7a5e2066de0647f6857970531798aa0c",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "a77883f394b1469b85bf95e7063c801d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "0c92b06575f14096ac774cc5f9d1150a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "073ad578cc214d75977c9f776752b882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2518c0de80646a9b3c7e81e3ee73134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ad76528decd4e1e90fabac6fb56dd0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "619d1c2f669e4ad9ad80f767df07997f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "365b7e8d60b640e4ab627604059a8bbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c366539f3d54521b8e1714f45d59c8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9c32d09fa104ab3ad1b28aa68b5a426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "0c371d9d75104fafa7cb38747455d59f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a5e2066de0647f6857970531798aa0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "beaa0bad81644cb3a04e1b3fd4f23cf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe216cb0a19c4d0a8dff48d2e55928ce",
            "placeholder": "​",
            "style": "IPY_MODEL_84cc12b0a5c849739035cecc42cfb885",
            "value": "Connecting..."
          }
        },
        "fe216cb0a19c4d0a8dff48d2e55928ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84cc12b0a5c849739035cecc42cfb885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46cd7df70af54771ae8bf79467d58d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5514705023e417aa5022c7c0638a182",
              "IPY_MODEL_fd708d22664f48748a56a5065cb6b2e4",
              "IPY_MODEL_5e6481011a114d249ff0dd8857ca491f"
            ],
            "layout": "IPY_MODEL_8d481038e9294685aa5ab1cd3be3a6ed"
          }
        },
        "a5514705023e417aa5022c7c0638a182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1f3ab5544534298a221ea6a9676ac7f",
            "placeholder": "​",
            "style": "IPY_MODEL_7ac33255bcec477b8a49985f2bb2db3f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "fd708d22664f48748a56a5065cb6b2e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffc7495b68204a32a58933f32a6c8303",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d85fabc9580f4f8aa5821c35095a3773",
            "value": 3
          }
        },
        "5e6481011a114d249ff0dd8857ca491f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0fc30e74564408a805352e0e6dddbe4",
            "placeholder": "​",
            "style": "IPY_MODEL_dd3cce7ef24a4610be1d9a5223560b4b",
            "value": " 3/3 [00:45&lt;00:00, 13.90s/it]"
          }
        },
        "8d481038e9294685aa5ab1cd3be3a6ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1f3ab5544534298a221ea6a9676ac7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ac33255bcec477b8a49985f2bb2db3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffc7495b68204a32a58933f32a6c8303": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d85fabc9580f4f8aa5821c35095a3773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0fc30e74564408a805352e0e6dddbe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd3cce7ef24a4610be1d9a5223560b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c3d5bd3c76047cbbc49b76a6a230b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_771755cd076d4171a0d2484c87ffaa15",
              "IPY_MODEL_c366bedff3d145b7b562a8fed6a90b35",
              "IPY_MODEL_f2f2253f8a754a63baf8b49661d91237"
            ],
            "layout": "IPY_MODEL_9757762468f54b44bf3845055488deb3"
          }
        },
        "771755cd076d4171a0d2484c87ffaa15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ea0abdc49324f2791b6b664a83edd43",
            "placeholder": "​",
            "style": "IPY_MODEL_39d72fb5a9404e0f9bd778465ca8dc14",
            "value": "Unsloth: Tokenizing [&quot;text&quot;] (num_proc=6): 100%"
          }
        },
        "c366bedff3d145b7b562a8fed6a90b35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28220530f9734bbb8fc2213b811363b9",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d03605e30dc04683bead9ee4af7de1c9",
            "value": 50000
          }
        },
        "f2f2253f8a754a63baf8b49661d91237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bde50ccab2c545b881e308aabce592c3",
            "placeholder": "​",
            "style": "IPY_MODEL_c54e82bb6a524b65ae77ec51c7b64b0d",
            "value": " 50000/50000 [00:33&lt;00:00, 2196.12 examples/s]"
          }
        },
        "9757762468f54b44bf3845055488deb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ea0abdc49324f2791b6b664a83edd43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39d72fb5a9404e0f9bd778465ca8dc14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28220530f9734bbb8fc2213b811363b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d03605e30dc04683bead9ee4af7de1c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bde50ccab2c545b881e308aabce592c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c54e82bb6a524b65ae77ec51c7b64b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c169aaaac069436d9fc2d56657df02b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0650c66ea38a4386bd505c5d3e259389",
              "IPY_MODEL_2d1836f615c349d7a60184cb80a490f0",
              "IPY_MODEL_74369c3cf1a1444eb6ca020b50a970fb"
            ],
            "layout": "IPY_MODEL_776f6ba2ba9d49b8a8c237b56e31eca1"
          }
        },
        "0650c66ea38a4386bd505c5d3e259389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adace6c1e33c44deaa53345b0fde748a",
            "placeholder": "​",
            "style": "IPY_MODEL_cd3f2b583576423c9242dd05035419bb",
            "value": "Unsloth: Tokenizing [&quot;text&quot;] (num_proc=6): 100%"
          }
        },
        "2d1836f615c349d7a60184cb80a490f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1a23f4c83f2475b9267a23b005c0a89",
            "max": 1001,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbeb158b7b29434b914b5945daadec8c",
            "value": 1001
          }
        },
        "74369c3cf1a1444eb6ca020b50a970fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2278e1b587b42579297371efba06310",
            "placeholder": "​",
            "style": "IPY_MODEL_5aa08fc7dbf34ab3a068403dac24cee5",
            "value": " 1001/1001 [00:12&lt;00:00, 118.91 examples/s]"
          }
        },
        "776f6ba2ba9d49b8a8c237b56e31eca1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adace6c1e33c44deaa53345b0fde748a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd3f2b583576423c9242dd05035419bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1a23f4c83f2475b9267a23b005c0a89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbeb158b7b29434b914b5945daadec8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2278e1b587b42579297371efba06310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aa08fc7dbf34ab3a068403dac24cee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "186eebe7edf94a03b56b3d123a3a9145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30877de354534927b8cef5d2d68c9c51",
              "IPY_MODEL_4bc3506511e84199a8c8d7bc626cc8c3",
              "IPY_MODEL_11ae09a8f72446a7b6ba6353ba9f72d5"
            ],
            "layout": "IPY_MODEL_1f7f003e443e46a9abea87f229d4a359"
          }
        },
        "30877de354534927b8cef5d2d68c9c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4b629d204e649fab2bd7a60ca84bf85",
            "placeholder": "​",
            "style": "IPY_MODEL_3f3510d8c5d24b49bb3ed7b58d3aa632",
            "value": "Map (num_proc=6): 100%"
          }
        },
        "4bc3506511e84199a8c8d7bc626cc8c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2852b6bd5c5b4ffc8235f3ab9f1ecae5",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_acc72f406d704fcd8d21f6636faa364c",
            "value": 50000
          }
        },
        "11ae09a8f72446a7b6ba6353ba9f72d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a593ad06ef5d40028f8f4e8815bf0d1d",
            "placeholder": "​",
            "style": "IPY_MODEL_1982efa8855c47b4b5ea0b8c84908e02",
            "value": " 50000/50000 [00:06&lt;00:00, 11218.93 examples/s]"
          }
        },
        "1f7f003e443e46a9abea87f229d4a359": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4b629d204e649fab2bd7a60ca84bf85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f3510d8c5d24b49bb3ed7b58d3aa632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2852b6bd5c5b4ffc8235f3ab9f1ecae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acc72f406d704fcd8d21f6636faa364c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a593ad06ef5d40028f8f4e8815bf0d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1982efa8855c47b4b5ea0b8c84908e02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "708229c6928b4a91a22e3e4e8ff93bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72f72e12f3794e6f9f0b1b46090cbcf5",
              "IPY_MODEL_8655fe6f6de349899669c7a6c81c8496",
              "IPY_MODEL_91e441cee617432bb1c7beb56b52f0be"
            ],
            "layout": "IPY_MODEL_9db2d400d914445aa3bbe697916efdc3"
          }
        },
        "72f72e12f3794e6f9f0b1b46090cbcf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_384aa24dd59f40f78dbe705ed83ade84",
            "placeholder": "​",
            "style": "IPY_MODEL_c3aae31f26e34644b331d187dac37019",
            "value": "Map (num_proc=6): 100%"
          }
        },
        "8655fe6f6de349899669c7a6c81c8496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fa9ddfd89b44be7b88da89772e8089c",
            "max": 1001,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec178a45461a433c89243aa76d678532",
            "value": 1001
          }
        },
        "91e441cee617432bb1c7beb56b52f0be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c45c6ce374b49f291bc8c8ef5e74cc4",
            "placeholder": "​",
            "style": "IPY_MODEL_ec30b1f7fc29431891a8cecebe58ad5f",
            "value": " 1001/1001 [00:00&lt;00:00, 2239.35 examples/s]"
          }
        },
        "9db2d400d914445aa3bbe697916efdc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "384aa24dd59f40f78dbe705ed83ade84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3aae31f26e34644b331d187dac37019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fa9ddfd89b44be7b88da89772e8089c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec178a45461a433c89243aa76d678532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c45c6ce374b49f291bc8c8ef5e74cc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec30b1f7fc29431891a8cecebe58ad5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 105267,
          "databundleVersionId": 12693789,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmaguero/diploma_fpuna_nlp_ia/blob/master/2025/Gemma_3N_4B_finetuning_with_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Competition](attachment:4ba23f21-a6df-45a7-b3ab-0460b9700288.png)](https://www.kaggle.com/competitions/google-gemma-3n-hackathon/overview)\n",
        "\n",
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Kaggle instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ⭐ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n",
        "\n",
        "Read our **[Gemma 3N Guide](https://docs.unsloth.ai/basics/gemma-3n-how-to-run-and-fine-tune)** and check out our new **[Dynamic 2.0](https://docs.unsloth.ai/basics/unsloth-dynamic-2.0-ggufs)** quants which outperforms other quantization methods!\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n",
        "\n",
        "## Gemma 3N Notebook collection:\n",
        "1. Gemma 3N **Multimodal inference + conversational finetuning** [Kaggle Notebook](https://www.kaggle.com/code/danielhanchen/gemma-3n-4b-multimodal-finetuning-inference) *⬅️ Your are here*\n",
        "2. Gemma 3N **Vision finetuning** [Kaggle Notebook](https://www.kaggle.com/code/danielhanchen/gemma-3n-4b-vision-finetuning)\n",
        "3. Gemma 3N **Audio finetuning** [Kaggle Notebook](https://www.kaggle.com/code/danielhanchen/gemma-3n-4b-audio-finetuning)"
      ],
      "metadata": {
        "id": "wh4ZpnndMvaO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installation"
      ],
      "metadata": {
        "id": "N3z2yeVsMvaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMZvUfRzLpJc",
        "outputId": "09af7239-5ded-41ab-8e11-f8aef123e2dc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Nov 23 11:00:41 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth\n",
        "    !pip install weave\n",
        "    !pip install rouge_score"
      ],
      "metadata": {
        "id": "pS-P_shPMvaX",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57a753de-9e31-4000-c56a-b6f7cbb32ab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.48.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: xformers==0.0.29.post3 in /usr/local/lib/python3.12/dist-packages (0.0.29.post3)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.12/dist-packages (0.25.1)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.12/dist-packages (3.5.0)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.12/dist-packages (25.1.1)\n",
            "Requirement already satisfied: unsloth_zoo in /usr/local/lib/python3.12/dist-packages (2025.11.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (5.29.5)\n",
            "Requirement already satisfied: datasets<4.0.0,>=3.4.1 in /usr/local/lib/python3.12/dist-packages (3.6.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (0.1.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1) (2025.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0) (1.2.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1) (3.13.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0.0,>=3.4.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0.0,>=3.4.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0.0,>=3.4.1) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<4.0.0,>=3.4.1) (1.17.0)\n",
            "Requirement already satisfied: unsloth in /usr/local/lib/python3.12/dist-packages (2025.11.3)\n",
            "Requirement already satisfied: weave in /usr/local/lib/python3.12/dist-packages (0.52.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from weave) (8.3.1)\n",
            "Requirement already satisfied: diskcache==5.6.3 in /usr/local/lib/python3.12/dist-packages (from weave) (5.6.3)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.12/dist-packages (from weave) (0.3.0)\n",
            "Requirement already satisfied: gql>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from gql[aiohttp,requests]>=3.0.0->weave) (4.0.0)\n",
            "Requirement already satisfied: jsonschema>=4.23.0 in /usr/local/lib/python3.12/dist-packages (from weave) (4.25.1)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.12/dist-packages (from weave) (25.0)\n",
            "Requirement already satisfied: polyfile-weave in /usr/local/lib/python3.12/dist-packages (from weave) (0.5.7)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from weave) (2.11.10)\n",
            "Requirement already satisfied: sentry-sdk<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from weave) (2.45.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,>=8.3.0 in /usr/local/lib/python3.12/dist-packages (from weave) (8.5.0)\n",
            "Requirement already satisfied: wandb>=0.17.1 in /usr/local/lib/python3.12/dist-packages (from weave) (0.23.0)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.2 in /usr/local/lib/python3.12/dist-packages (from gql>=3.0.0->gql[aiohttp,requests]>=3.0.0->weave) (3.2.7)\n",
            "Requirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.12/dist-packages (from gql>=3.0.0->gql[aiohttp,requests]>=3.0.0->weave) (1.22.0)\n",
            "Requirement already satisfied: backoff<3.0,>=1.11.1 in /usr/local/lib/python3.12/dist-packages (from gql>=3.0.0->gql[aiohttp,requests]>=3.0.0->weave) (2.2.1)\n",
            "Requirement already satisfied: anyio<5,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gql>=3.0.0->gql[aiohttp,requests]>=3.0.0->weave) (4.11.0)\n",
            "Requirement already satisfied: aiohttp<4,>=3.11.2 in /usr/local/lib/python3.12/dist-packages (from gql[aiohttp,requests]>=3.0.0->weave) (3.13.2)\n",
            "Requirement already satisfied: requests<3,>=2.26 in /usr/local/lib/python3.12/dist-packages (from gql[aiohttp,requests]>=3.0.0->weave) (2.32.4)\n",
            "Requirement already satisfied: requests_toolbelt<2,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from gql[aiohttp,requests]>=3.0.0->weave) (1.0.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.23.0->weave) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.23.0->weave) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.23.0->weave) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.23.0->weave) (0.29.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->weave) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->weave) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->weave) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->weave) (0.4.2)\n",
            "Requirement already satisfied: urllib3>=1.26.11 in /usr/local/lib/python3.12/dist-packages (from sentry-sdk<3.0.0,>=2.0.0->weave) (2.5.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from sentry-sdk<3.0.0,>=2.0.0->weave) (2025.11.12)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.17.1->weave) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb>=0.17.1->weave) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.17.1->weave) (5.29.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb>=0.17.1->weave) (6.0.3)\n",
            "Requirement already satisfied: abnf~=2.2.0 in /usr/local/lib/python3.12/dist-packages (from polyfile-weave->weave) (2.2.0)\n",
            "Requirement already satisfied: chardet>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from polyfile-weave->weave) (5.2.0)\n",
            "Requirement already satisfied: cint>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from polyfile-weave->weave) (1.0.0)\n",
            "Requirement already satisfied: fickling>=0.0.8 in /usr/local/lib/python3.12/dist-packages (from polyfile-weave->weave) (0.1.5)\n",
            "Requirement already satisfied: graphviz>=0.20.1 in /usr/local/lib/python3.12/dist-packages (from polyfile-weave->weave) (0.21)\n",
            "Requirement already satisfied: intervaltree>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from polyfile-weave->weave) (3.1.0)\n",
            "Requirement already satisfied: jinja2>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from polyfile-weave->weave) (3.1.6)\n",
            "Requirement already satisfied: kaitaistruct~=0.10 in /usr/local/lib/python3.12/dist-packages (from polyfile-weave->weave) (0.11)\n",
            "Requirement already satisfied: networkx>=2.6.3 in /usr/local/lib/python3.12/dist-packages (from polyfile-weave->weave) (3.5)\n",
            "Requirement already satisfied: pdfminer.six<=20250506,>=20220524 in /usr/local/lib/python3.12/dist-packages (from polyfile-weave->weave) (20250506)\n",
            "Requirement already satisfied: Pillow>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from polyfile-weave->weave) (11.3.0)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from polyfile-weave->weave) (80.9.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.11.2->gql[aiohttp,requests]>=3.0.0->weave) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.11.2->gql[aiohttp,requests]>=3.0.0->weave) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.11.2->gql[aiohttp,requests]>=3.0.0->weave) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.11.2->gql[aiohttp,requests]>=3.0.0->weave) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.11.2->gql[aiohttp,requests]>=3.0.0->weave) (0.4.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.0->gql>=3.0.0->gql[aiohttp,requests]>=3.0.0->weave) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.0->gql>=3.0.0->gql[aiohttp,requests]>=3.0.0->weave) (1.3.1)\n",
            "Requirement already satisfied: stdlib-list~=0.11.1 in /usr/local/lib/python3.12/dist-packages (from fickling>=0.0.8->polyfile-weave->weave) (0.11.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.17.1->weave) (4.0.12)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from intervaltree>=2.4.0->polyfile-weave->weave) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=2.1.0->polyfile-weave->weave) (3.0.3)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six<=20250506,>=20220524->polyfile-weave->weave) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six<=20250506,>=20220524->polyfile-weave->weave) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six<=20250506,>=20220524->polyfile-weave->weave) (2.0.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.17.1->weave) (5.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six<=20250506,>=20220524->polyfile-weave->weave) (2.23)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (4.67.1)\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "#%%capture\n",
        "# Install latest transformers for Gemma 3N\n",
        "!pip install --no-deps --upgrade transformers # Only for Gemma 3N\n",
        "!pip install --no-deps --upgrade timm # Only for Gemma 3N"
      ],
      "metadata": {
        "id": "lBN09c1tUlSV",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41a4a41c-7d6f-4511-d6e2-0acf111913fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.22)\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "We encourage you to login to your Hugging Face account so you can upload and share your model with the community. When prompted, enter your token to login:"
      ],
      "metadata": {
        "id": "EXnUC_ejQqFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "v57F0qTtQjNg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "77a254c98dd24c8f90df9ebef6eeca48",
            "17b8357518254c9dbb5ed08945d40772",
            "24f08955b08945f7933e141c2bd92d86",
            "ffc37ad2eb8a4d849b4e15e1a9bc2ddb",
            "8a2ed8fb1df0486597d23909f63a05c5",
            "eef3d82b08a54c0ab714608cddc17a3e",
            "a77883f394b1469b85bf95e7063c801d",
            "0c92b06575f14096ac774cc5f9d1150a",
            "073ad578cc214d75977c9f776752b882",
            "e2518c0de80646a9b3c7e81e3ee73134",
            "1ad76528decd4e1e90fabac6fb56dd0a",
            "619d1c2f669e4ad9ad80f767df07997f",
            "365b7e8d60b640e4ab627604059a8bbf",
            "3c366539f3d54521b8e1714f45d59c8a",
            "b9c32d09fa104ab3ad1b28aa68b5a426",
            "0c371d9d75104fafa7cb38747455d59f",
            "7a5e2066de0647f6857970531798aa0c",
            "beaa0bad81644cb3a04e1b3fd4f23cf1",
            "fe216cb0a19c4d0a8dff48d2e55928ce",
            "84cc12b0a5c849739035cecc42cfb885"
          ]
        },
        "outputId": "928585cd-559f-47f7-c9db-81ad79448bba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77a254c98dd24c8f90df9ebef6eeca48"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unsloth\n",
        "\n",
        "`FastModel` supports loading nearly any model now! This includes Vision, Text and Audio models!"
      ],
      "metadata": {
        "id": "TGMWlrRdzwgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastModel\n",
        "import torch\n",
        "\n",
        "fourbit_models = [\n",
        "    # 4bit dynamic quants for superior accuracy and low memory use\n",
        "    \"unsloth/gemma-3n-E4B-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3n-E2B-it-unsloth-bnb-4bit\",\n",
        "    # Pretrained models\n",
        "    \"unsloth/gemma-3n-E4B-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3n-E2B-unsloth-bnb-4bit\",\n",
        "\n",
        "    # Other Gemma 3 quants\n",
        "    \"unsloth/gemma-3-1b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-12b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-27b-it-unsloth-bnb-4bit\",\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastModel.from_pretrained(\n",
        "    model_name = \"google/gemma-3n-E4B-it\", # \"google/gemma-3n-E2B-it\" or \"unsloth/gemma-3n-E4B-it\", # Or \"unsloth/gemma-3n-E2B-it\"\n",
        "    dtype = None, # None for auto detection\n",
        "    max_seq_length = 1024, # or 768-512-256-128... Choose any for long context!\n",
        "    load_in_4bit = True,  # 4 bit quantization to reduce memory\n",
        "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
        "    # token = \"hf_...\", # use one if using gated models\n",
        ")"
      ],
      "metadata": {
        "id": "-Xbb0cuLzwgf",
        "outputId": "afbf37e1-117e-4072-bc40-5e2a2d0c8d30",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659,
          "referenced_widgets": [
            "46cd7df70af54771ae8bf79467d58d1a",
            "a5514705023e417aa5022c7c0638a182",
            "fd708d22664f48748a56a5065cb6b2e4",
            "5e6481011a114d249ff0dd8857ca491f",
            "8d481038e9294685aa5ab1cd3be3a6ed",
            "f1f3ab5544534298a221ea6a9676ac7f",
            "7ac33255bcec477b8a49985f2bb2db3f",
            "ffc7495b68204a32a58933f32a6c8303",
            "d85fabc9580f4f8aa5821c35095a3773",
            "c0fc30e74564408a805352e0e6dddbe4",
            "dd3cce7ef24a4610be1d9a5223560b4b"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1425262414.py:1: UserWarning: WARNING: Unsloth should be imported before transformers to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
            "\n",
            "Please restructure your imports with 'import unsloth' at the top of your file.\n",
            "  from unsloth import FastModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.6.0+cu124 with CUDA 1204 (you have 2.9.0+cu126)\n",
            "    Python  3.12.9 (you have 3.12.12)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========\n",
            "Switching to PyTorch attention since your Xformers is broken.\n",
            "========\n",
            "\n",
            "Unsloth: Xformers was not installed correctly.\n",
            "Please install xformers separately first.\n",
            "Then confirm if it's correctly installed by running:\n",
            "python -m xformers.info\n",
            "\n",
            "Longer error message:\n",
            "xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.6.0+cu124 with CUDA 1204 (you have 2.9.0+cu126)\n",
            "    Python  3.12.9 (you have 3.12.12)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.11.3: Fast Gemma3N patching. Transformers: 4.57.1.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: Using float16 precision for gemma3n won't work! Using float32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46cd7df70af54771ae8bf79467d58d1a"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemma 3N can process Text, Vision and Audio!\n",
        "\n",
        "Let's first experience how Gemma 3N can handle multimodal inputs. We use Gemma 3N's recommended settings of `temperature = 1.0, top_p = 0.95, top_k = 64`"
      ],
      "metadata": {
        "id": "ixr4dyTHVIcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextStreamer\n",
        "import gc\n",
        "# Helper function for inference\n",
        "def do_gemma_3n_inference(model, messages, max_new_tokens = 128):\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt = True, # Must add for generation\n",
        "        tokenize = True,\n",
        "        return_dict = True,\n",
        "        return_tensors = \"pt\",\n",
        "    ).to(\"cuda\")\n",
        "    _ = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens = max_new_tokens,\n",
        "        temperature = 1.0, top_p = 0.95, top_k = 64,\n",
        "        streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
        "    )\n",
        "    # Cleanup to reduce VRAM usage\n",
        "    del inputs\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()"
      ],
      "metadata": {
        "id": "UsfUPU-oVQYu",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemma 3N can see images!\n",
        "\n",
        "<img src=\"https://files.worldwildlife.org/wwfcmsprod/images/Sloth_Sitting_iStock_3_12_2014/story_full_width/8l7pbjmj29_iStock_000011145477Large_mini__1_.jpg\" alt=\"Alt text\" height=\"256\">"
      ],
      "metadata": {
        "id": "q2-ddk0CWeTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sloth_link = \"https://files.worldwildlife.org/wwfcmsprod/images/Sloth_Sitting_iStock_3_12_2014/story_full_width/8l7pbjmj29_iStock_000011145477Large_mini__1_.jpg\"\n",
        "\n",
        "messages = [{\n",
        "    \"role\" : \"user\",\n",
        "    \"content\": [\n",
        "        { \"type\": \"image\", \"image\" : sloth_link },\n",
        "        { \"type\": \"text\",  \"text\" : \"Mba'e pelíkulapepa osë ko mymba?\" }\n",
        "    ]\n",
        "}]\n",
        "# You might have to wait 1 minute for Unsloth's auto compiler\n",
        "do_gemma_3n_inference(model, messages, max_new_tokens = 256)"
      ],
      "metadata": {
        "id": "9jGeSb9bWe0k",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's make a poem about sloths!"
      ],
      "metadata": {
        "id": "eh0BzbZPWtRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": [{ \"type\" : \"text\",\n",
        "                  \"text\" : \"Ehai peteĩ ñe'ẽpoty perezoso (peteï mymba ojoguáva Mapinguari-pe) peguara: \" }]\n",
        "}]\n",
        "do_gemma_3n_inference(model, messages, max_new_tokens = 128)"
      ],
      "metadata": {
        "id": "R3ExuK8cWuT3",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemma 3N can also hear!"
      ],
      "metadata": {
        "id": "wZrmFRZpZtGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio, display\n",
        "Audio(\"https://www.nasa.gov/wp-content/uploads/2015/01/591240main_JFKmoonspeech.mp3\")"
      ],
      "metadata": {
        "id": "68crYajNZtw1",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -qqq https://www.nasa.gov/wp-content/uploads/2015/01/591240main_JFKmoonspeech.mp3 -O audio.mp3"
      ],
      "metadata": {
        "id": "k3vrdoa0Z01X",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file = \"audio.mp3\"\n",
        "\n",
        "messages = [{\n",
        "    \"role\" : \"user\",\n",
        "    \"content\": [\n",
        "        { \"type\": \"audio\", \"audio\" : audio_file },\n",
        "        { \"type\": \"text\",  \"text\" : \"Mba'érehepa oñe'ẽ ko audio?\" }\n",
        "    ]\n",
        "}]\n",
        "do_gemma_3n_inference(model, messages, max_new_tokens = 256)"
      ],
      "metadata": {
        "id": "BJr_D4O9Z2Zh",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's combine all 3 modalities together!"
      ],
      "metadata": {
        "id": "L15JuAmmaOkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\n",
        "    \"role\" : \"user\",\n",
        "    \"content\": [\n",
        "        { \"type\": \"audio\", \"audio\" : audio_file },\n",
        "        { \"type\": \"image\", \"image\" : sloth_link },\n",
        "        { \"type\": \"text\",  \"text\" : \"Mba'érehepa oñe'ẽ ko audio ha ta'anga? \"\\\n",
        "                                    \"Mba'éichapa ojoaju hikuái?\" }\n",
        "    ]\n",
        "}]\n",
        "do_gemma_3n_inference(model, messages, max_new_tokens = 256)"
      ],
      "metadata": {
        "id": "is37bsDZaRwV",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's finetune Gemma 3N!\n",
        "\n",
        "You can finetune the vision and text parts for now through selection - the audio part can also be finetuned - we're working to make it selectable as well!"
      ],
      "metadata": {
        "id": "Bw5XPyYFajyM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now add LoRA adapters so we only need to update a small amount of parameters!"
      ],
      "metadata": {
        "id": "SXd9bTZd1aaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastModel.get_peft_model(\n",
        "    model,\n",
        "    finetune_vision_layers     = False, # Turn off for just text!\n",
        "    finetune_language_layers   = True,  # Should leave on!\n",
        "    finetune_attention_modules = True,  # Attention good for GRPO\n",
        "    finetune_mlp_modules       = True,  # Should leave on always!\n",
        "\n",
        "    r = 4,           # 4-8-16..., Larger = higher accuracy, but might overfit\n",
        "    lora_alpha = 4,  # 4-8-16..., Recommended alpha == r at least\n",
        "    lora_dropout = 0, # increase if the model overfit\n",
        "    bias = \"none\", # or lora-only\n",
        "    random_state = 42, #3407,\n",
        ")"
      ],
      "metadata": {
        "id": "6bZsfBuZDeCL",
        "outputId": "794bd9d2-0266-4d35-b9e3-aac801489da0",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Making `model.base_model.model.model.language_model` require gradients\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "We now use the `Gemma-3` format for conversation style finetunes. We use [Maxime Labonne's FineTome-100k](https://huggingface.co/datasets/mlabonne/FineTome-100k) dataset in ShareGPT style. Gemma-3 renders multi turn conversations like below:\n",
        "\n",
        "```\n",
        "<bos><start_of_turn>user\n",
        "Hello!<end_of_turn>\n",
        "<start_of_turn>model\n",
        "Hey there!<end_of_turn>\n",
        "```\n",
        "\n",
        "We use our `get_chat_template` function to get the correct chat template. We support `zephyr, chatml, mistral, llama, alpaca, vicuna, vicuna_old, phi3, llama3, phi4, qwen2.5, gemma3` and more."
      ],
      "metadata": {
        "id": "vITh0KVJ10qX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"gemma-3\",\n",
        ")"
      ],
      "metadata": {
        "id": "LjY75GoYUCB8",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "We get the first 3000 rows of the dataset"
      ],
      "metadata": {
        "id": "ZQkXuGYxbJ-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "#dataset = load_dataset(\"mlabonne/FineTome-100k\", split = \"train[:3000]\")\n",
        "dataset = load_dataset(\"rubuntu/dataset-guarani-jopara-v01\")"
      ],
      "metadata": {
        "id": "Mkq4RvEq7FQr",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now use `standardize_data_formats` to try converting datasets to the correct format for finetuning purposes!"
      ],
      "metadata": {
        "id": "K9CBpiISFa6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.chat_templates import standardize_data_formats\n",
        "dataset_train = standardize_data_formats(dataset[\"train\"])"
      ],
      "metadata": {
        "id": "reoBXmAn7HlN",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dev = standardize_data_formats(dataset[\"validation\"])"
      ],
      "metadata": {
        "id": "k4NjfkJJhQvU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test = standardize_data_formats(dataset[\"test\"])"
      ],
      "metadata": {
        "id": "Z183Rvw7hTZA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how row 100 looks like!"
      ],
      "metadata": {
        "id": "6i5Sx9In7vHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train[100]"
      ],
      "metadata": {
        "id": "dzE1OEXi7s3P",
        "outputId": "f307983d-6d14-48e9-8cb1-b5482bd46524",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'instruction': \"Diseña peteî base de datos oregistra haguã mba'apohára sueldo.\",\n",
              " 'input': '',\n",
              " 'output': \"Pe base de datos oguerekova’erã umi campo mba’apohara réra, cargo, sueldo ha ára rehegua. Avei oikeva'erã peteî campo mba'apohára sambyhyhárape guarã, ikatu haguã umi sueldo oñemboja'o hekoitépe departamento-kuéra rupi. Avei base de datos ikatuva'erã ogenera informe gasto salarial rehegua umi departamento térã tapichakuérape guarã.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have to apply the chat template for `Gemma-3` onto the conversations, and save it to `text`. We remove the `<bos>` token using removeprefix(`'<bos>'`) since we're finetuning. The Processor will add this token before training and the model expects only one."
      ],
      "metadata": {
        "id": "8Xs0LXio7rfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def formatting_prompts_func(examples):\n",
        "   convos_1 = examples[\"instruction\"]\n",
        "   convos_2 = examples[\"input\"]\n",
        "   convos_3 = examples[\"output\"]\n",
        "\n",
        "   texts = []\n",
        "   for i in range(len(convos_1)):\n",
        "       # Ensure content parts are strings, replacing None with empty string\n",
        "       instruction_part = str(convos_1[i]) if convos_1[i] is not None else \"\"\n",
        "       input_part = str(convos_2[i]) if convos_2[i] is not None else \"\"\n",
        "       output_part = str(convos_3[i]) if convos_3[i] is not None else \"\"\n",
        "\n",
        "       user_content = instruction_part\n",
        "       if input_part: # Only add input if it's not empty\n",
        "           user_content += \" \" + input_part\n",
        "\n",
        "       # Apply chat template with robust content\n",
        "       full_text = tokenizer.apply_chat_template(\n",
        "           [\n",
        "               {'role': 'user', 'content': [{'type': 'text', 'text': user_content}]},\n",
        "               {'role': 'assistant', 'content': [{'type': 'text', 'text': output_part}]},\n",
        "           ],\n",
        "           tokenize = False,\n",
        "           add_generation_prompt = False\n",
        "       ).removeprefix('<bos>')\n",
        "       texts.append(full_text)\n",
        "   return { \"text\" : texts, }\n",
        "\n",
        "dataset_train = dataset_train.map(formatting_prompts_func, batched = True)\n",
        "dataset_dev = dataset_dev.map(formatting_prompts_func, batched = True)\n",
        "dataset_test = dataset_test.map(formatting_prompts_func, batched = True)"
      ],
      "metadata": {
        "id": "1ahE8Ys37JDJ",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how the chat template did! Notice there is no `<bos>` token as the processor tokenizer will be adding one."
      ],
      "metadata": {
        "id": "ndDUB23CGAC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train[100][\"text\"]"
      ],
      "metadata": {
        "id": "gGFzmplrEy9I",
        "outputId": "0e9de249-18bc-4fc4-bffe-0539dbe8e92b",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<start_of_turn>user\\nDiseña peteî base de datos oregistra haguã mba'apohára sueldo.<end_of_turn>\\n<start_of_turn>model\\nPe base de datos oguerekova’erã umi campo mba’apohara réra, cargo, sueldo ha ára rehegua. Avei oikeva'erã peteî campo mba'apohára sambyhyhárape guarã, ikatu haguã umi sueldo oñemboja'o hekoitépe departamento-kuéra rupi. Avei base de datos ikatuva'erã ogenera informe gasto salarial rehegua umi departamento térã tapichakuérape guarã.<end_of_turn>\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`."
      ],
      "metadata": {
        "id": "idAEIeSQ3xdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install evaluate bert_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlYzS9MnnhGS",
        "outputId": "90102ffb-235e-484d-bda1-1ce072456198"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from bert_score) (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from bert_score) (4.57.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from bert_score) (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert_score) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert_score) (0.7.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert_score) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert_score) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert_score) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert_score) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert_score) (3.2.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.3)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate, bert_score\n",
            "Successfully installed bert_score-0.3.13 evaluate-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import EvalPrediction\n",
        "import numpy as np\n",
        "import evaluate\n",
        "# For METEOR and BLEU, NLTK data is required\n",
        "import nltk\n",
        "# Ensure punkt and wordnet are downloaded for tokenization and stemming required by METEOR/BLEU\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    nltk.download('punkt', quiet=True)\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    nltk.download('wordnet', quiet=True)\n",
        "\n",
        "\n",
        "# Load metrics outside the function to avoid re-loading repeatedly\n",
        "# bertscore requires internet access the first time it runs to download a model (e.g., 'bert-base-uncased')\n",
        "try:\n",
        "    bertscore_metric = evaluate.load(\"bertscore\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not load BERTScore. Ensure internet is available for initial download: {e}\")\n",
        "    bertscore_metric = None\n",
        "\n",
        "try:\n",
        "    meteor_metric = evaluate.load(\"meteor\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not load METEOR. Ensure nltk data is downloaded: {e}\")\n",
        "    meteor_metric = None\n",
        "\n",
        "try:\n",
        "    rouge_metric = evaluate.load(\"rouge\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not load ROUGE. Ensure internet is available for initial download: {e}\")\n",
        "    rouge_metric = None\n",
        "\n",
        "# Note: The tokenizer must be accessible in this scope for the decode function to work.\n",
        "# Assuming 'tokenizer' is defined globally where this function runs.\n",
        "\n",
        "########################\n",
        "# Disabled for RAM/GPU #\n",
        "########################\n",
        "# None = disabled\n",
        "bertscore_metric = None\n",
        "meteor_metric = None\n",
        "#rouge_metric = None\n",
        "########################\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    logits = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "    pred_ids = np.argmax(logits, axis=-1)\n",
        "    label_ids = p.label_ids\n",
        "\n",
        "    decoded_preds = []\n",
        "    decoded_labels = []\n",
        "\n",
        "    for i in range(len(label_ids)):\n",
        "        # For references (labels):\n",
        "        actual_label_tokens = label_ids[i][label_ids[i] != -100]\n",
        "        if len(actual_label_tokens) > 0:\n",
        "            decoded_label = tokenizer.decode(actual_label_tokens, skip_special_tokens=True)\n",
        "            decoded_labels.append(decoded_label)\n",
        "        else:\n",
        "            decoded_labels.append(\"\")\n",
        "\n",
        "        # For predictions:\n",
        "        response_start_idx = np.where(label_ids[i] != -100)\n",
        "        if len(response_start_idx) > 0 and len(response_start_idx[0]) > 0:\n",
        "            response_start_idx = response_start_idx[0][0]\n",
        "            predicted_response_tokens = pred_ids[i][response_start_idx:]\n",
        "            decoded_pred = tokenizer.decode(predicted_response_tokens, skip_special_tokens=True)\n",
        "            decoded_preds.append(decoded_pred)\n",
        "        else:\n",
        "            decoded_preds.append(\"\")\n",
        "\n",
        "    # Filter out empty strings which can cause issues with metric computation\n",
        "    filtered_decoded_labels = [text for text in decoded_labels if text.strip()]\n",
        "    filtered_decoded_preds = [text for text in decoded_preds if text.strip()]\n",
        "\n",
        "    # Handle cases where there are no valid samples for metric computation\n",
        "    if not filtered_decoded_labels or not filtered_decoded_preds:\n",
        "        return {\n",
        "            \"meteor\": 0.0,\n",
        "            \"bertscore_f1\": 0.0,\n",
        "            \"rouge_f1\": 0.0\n",
        "        }\n",
        "\n",
        "    metrics = {}\n",
        "\n",
        "    # METEOR (Requires NLTK downloads, faster than BERTScore, better than ROUGE/BLEU)\n",
        "    if meteor_metric:\n",
        "        meteor_results = meteor_metric.compute(predictions=filtered_decoded_preds,\n",
        "                                              references=filtered_decoded_labels)\n",
        "        metrics[\"meteor\"] = meteor_results[\"meteor\"]\n",
        "\n",
        "    # BERTScore (Slower due to loading/running a BERT model for embeddings, best semantic metric here)\n",
        "    if bertscore_metric:\n",
        "        # Lang parameter is crucial. If text is English, 'en' is default.\n",
        "        # Ensure you handle different languages if necessary.\n",
        "        bert_results = bertscore_metric.compute(predictions=filtered_decoded_preds,\n",
        "                                                references=filtered_decoded_labels,\n",
        "                                                model_type=\"microsoft/deberta-base-mnli\",\n",
        "                                                #lang=\"en\"\n",
        "                                                )\n",
        "        # BERTScore returns precision, recall, and f1 for each sample. We average the F1 scores.\n",
        "        metrics[\"bertscore_f1\"] = np.mean(bert_results[\"f1\"])\n",
        "\n",
        "    # ROUGE (Lightweight metric)\n",
        "    if rouge_metric:\n",
        "        rouge_results = rouge_metric.compute(predictions=filtered_decoded_preds,\n",
        "                                             references=filtered_decoded_labels)\n",
        "        # Using rougeL for overall summary, can use rouge1 or rouge2 as well\n",
        "        metrics[\"rouge_f1\"] = rouge_results[\"rougeL\"].mid.fmeasure\n",
        "\n",
        "    # Combined metric calculation\n",
        "    combined_score_sum = 0.0\n",
        "    active_metric_count = 0\n",
        "\n",
        "    if \"meteor\" in metrics:\n",
        "        combined_score_sum += metrics[\"meteor\"]\n",
        "        active_metric_count += 1\n",
        "    if \"bertscore_f1\" in metrics:\n",
        "        combined_score_sum += metrics[\"bertscore_f1\"]\n",
        "        active_metric_count += 1\n",
        "    if \"rouge_f1\" in metrics:\n",
        "        combined_score_sum += metrics[\"rouge_f1\"]\n",
        "        active_metric_count += 1\n",
        "\n",
        "    metrics[\"combined\"] = combined_score_sum / active_metric_count if active_metric_count > 0 else 0.0\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "xouI1sYMt3DC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f3f61de-118f-4573-d108-364a9b5af5ff"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**********************************************************************\n",
            "  Resource \u001b[93mwordnet\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('wordnet')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainerCallback\n",
        "import psutil\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# Define the MemoryMonitorCallback class as provided by the user\n",
        "class MemoryMonitorCallback(TrainerCallback):\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        # Python process RAM usage\n",
        "        process = psutil.Process(os.getpid())\n",
        "        python_ram_mb = process.memory_info().rss / (1024 ** 2)\n",
        "\n",
        "        # GPU VRAM usage\n",
        "        if torch.cuda.is_available():\n",
        "            gpu_allocated_mb = torch.cuda.memory_allocated() / (1024 ** 2)\n",
        "            gpu_max_allocated_mb = torch.cuda.max_memory_allocated() / (1024 ** 2)\n",
        "            print(f\"\\nStep {state.global_step}: Python RAM = {python_ram_mb:.2f} MB, GPU Allocated = {gpu_allocated_mb:.2f} MB, GPU Max Allocated = {gpu_max_allocated_mb:.2f} MB\")\n",
        "        else:\n",
        "            print(f\"\\nStep {state.global_step}: Python RAM = {python_ram_mb:.2f} MB\")\n",
        "\n",
        "# Instantiate the callback\n",
        "memory_monitor_callback = MemoryMonitorCallback()"
      ],
      "metadata": {
        "id": "NMn2PmAQGaAK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer, SFTConfig\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset_train,\n",
        "    eval_dataset = dataset_dev, # Can set up evaluation!\n",
        "    #compute_metrics = compute_metrics, # Now includes ROUGE and BLEU!\n",
        "    callbacks=[memory_monitor_callback], # Add the custom callback here\n",
        "    #\n",
        "    args = SFTConfig(\n",
        "        dataset_text_field = \"text\",\n",
        "        per_device_train_batch_size = 1,\n",
        "        gradient_accumulation_steps = 16, # 2-4-8-16... Use GA to mimic batch size!\n",
        "        warmup_steps = 5,\n",
        "        #num_train_epochs = 1, # 3, Set this for full training run.\n",
        "        max_steps = 600, # 10\n",
        "        learning_rate = 2e-4, # Reduce to 2e-5 for long training runs\n",
        "        logging_steps = 175, # 10\n",
        "        optim = \"paged_adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 42,\n",
        "        report_to = \"wandb\", # Use this for WandB etc\n",
        "        do_eval=True,\n",
        "        eval_strategy=\"steps\", # epoch if num_train_epochs\n",
        "        eval_steps=175, # 10\n",
        "        #metric_for_best_model=\"combined\",\n",
        "        #greater_is_better=True, # loss -> lo contrario\n",
        "        gradient_checkpointing = True, # New: Enable gradient checkpointing\n",
        "        remove_unused_columns=True, # for test\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "95_Nn-89DhsL",
        "outputId": "5800df3c-a374-42a4-d20e-33a188873668",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "9c3d5bd3c76047cbbc49b76a6a230b31",
            "771755cd076d4171a0d2484c87ffaa15",
            "c366bedff3d145b7b562a8fed6a90b35",
            "f2f2253f8a754a63baf8b49661d91237",
            "9757762468f54b44bf3845055488deb3",
            "0ea0abdc49324f2791b6b664a83edd43",
            "39d72fb5a9404e0f9bd778465ca8dc14",
            "28220530f9734bbb8fc2213b811363b9",
            "d03605e30dc04683bead9ee4af7de1c9",
            "bde50ccab2c545b881e308aabce592c3",
            "c54e82bb6a524b65ae77ec51c7b64b0d",
            "c169aaaac069436d9fc2d56657df02b4",
            "0650c66ea38a4386bd505c5d3e259389",
            "2d1836f615c349d7a60184cb80a490f0",
            "74369c3cf1a1444eb6ca020b50a970fb",
            "776f6ba2ba9d49b8a8c237b56e31eca1",
            "adace6c1e33c44deaa53345b0fde748a",
            "cd3f2b583576423c9242dd05035419bb",
            "e1a23f4c83f2475b9267a23b005c0a89",
            "dbeb158b7b29434b914b5945daadec8c",
            "b2278e1b587b42579297371efba06310",
            "5aa08fc7dbf34ab3a068403dac24cee5"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Switching to float32 training since model cannot work with float16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c3d5bd3c76047cbbc49b76a6a230b31"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/1001 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c169aaaac069436d9fc2d56657df02b4"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also use Unsloth's `train_on_completions` method to only train on the assistant outputs and ignore the loss on the user's inputs. This helps increase accuracy of finetunes!"
      ],
      "metadata": {
        "id": "C_sGp5XlG6dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.chat_templates import train_on_responses_only\n",
        "trainer = train_on_responses_only(\n",
        "    trainer,\n",
        "    instruction_part = \"<start_of_turn>user\\n\",\n",
        "    response_part = \"<start_of_turn>model\\n\",\n",
        ")"
      ],
      "metadata": {
        "id": "juQiExuBG5Bt",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "186eebe7edf94a03b56b3d123a3a9145",
            "30877de354534927b8cef5d2d68c9c51",
            "4bc3506511e84199a8c8d7bc626cc8c3",
            "11ae09a8f72446a7b6ba6353ba9f72d5",
            "1f7f003e443e46a9abea87f229d4a359",
            "e4b629d204e649fab2bd7a60ca84bf85",
            "3f3510d8c5d24b49bb3ed7b58d3aa632",
            "2852b6bd5c5b4ffc8235f3ab9f1ecae5",
            "acc72f406d704fcd8d21f6636faa364c",
            "a593ad06ef5d40028f8f4e8815bf0d1d",
            "1982efa8855c47b4b5ea0b8c84908e02",
            "708229c6928b4a91a22e3e4e8ff93bf9",
            "72f72e12f3794e6f9f0b1b46090cbcf5",
            "8655fe6f6de349899669c7a6c81c8496",
            "91e441cee617432bb1c7beb56b52f0be",
            "9db2d400d914445aa3bbe697916efdc3",
            "384aa24dd59f40f78dbe705ed83ade84",
            "c3aae31f26e34644b331d187dac37019",
            "2fa9ddfd89b44be7b88da89772e8089c",
            "ec178a45461a433c89243aa76d678532",
            "6c45c6ce374b49f291bc8c8ef5e74cc4",
            "ec30b1f7fc29431891a8cecebe58ad5f"
          ]
        },
        "outputId": "fa81cf7e-0d5e-445d-a856-849ba0ad1e08"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=6):   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "186eebe7edf94a03b56b3d123a3a9145"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=6):   0%|          | 0/1001 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "708229c6928b4a91a22e3e4e8ff93bf9"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's verify masking the instruction part is done! Let's print the 100th row again.  Notice how the sample only has a single `<bos>` as expected!"
      ],
      "metadata": {
        "id": "Dv1NBUozV78l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(trainer.train_dataset[100][\"input_ids\"])"
      ],
      "metadata": {
        "id": "LtsMVtlkUhja",
        "outputId": "58ed8b67-1fe0-49cf-c13e-fc83011dfedb",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<bos><start_of_turn>user\\nDiseña peteî base de datos oregistra haguã mba'apohára sueldo.<end_of_turn>\\n<start_of_turn>model\\nPe base de datos oguerekova’erã umi campo mba’apohara réra, cargo, sueldo ha ára rehegua. Avei oikeva'erã peteî campo mba'apohára sambyhyhárape guarã, ikatu haguã umi sueldo oñemboja'o hekoitépe departamento-kuéra rupi. Avei base de datos ikatuva'erã ogenera informe gasto salarial rehegua umi departamento térã tapichakuérape guarã.<end_of_turn>\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's print the masked out example - you should see only the answer is present:"
      ],
      "metadata": {
        "id": "4Kyjy__m9KY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode([tokenizer.pad_token_id if x == -100 else x for x in trainer.train_dataset[100][\"labels\"]]).replace(tokenizer.pad_token, \" \")"
      ],
      "metadata": {
        "id": "_rD6fl8EUxnG",
        "outputId": "76fce09c-afb2-4404-aa45-0763e2b0d0d2",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"                               Pe base de datos oguerekova’erã umi campo mba’apohara réra, cargo, sueldo ha ára rehegua. Avei oikeva'erã peteî campo mba'apohára sambyhyhárape guarã, ikatu haguã umi sueldo oñemboja'o hekoitépe departamento-kuéra rupi. Avei base de datos ikatuva'erã ogenera informe gasto salarial rehegua umi departamento térã tapichakuérape guarã.<end_of_turn>\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "execution_count": 22
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Show current memory stats\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ],
      "metadata": {
        "id": "2ejIt2xSNKKp",
        "outputId": "e82ca333-0d57-40be-a8f7-54617d4018f9",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "13.629 GB of memory reserved.\n"
          ]
        }
      ],
      "execution_count": 23
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's train the model!\n",
        "\n",
        "To resume a training run, set `trainer.train(resume_from_checkpoint = True)`"
      ],
      "metadata": {
        "id": "CNP1Uidk9mrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "id": "yqxqAZ7KJ4oL",
        "outputId": "1678c382-2e41-4a8c-b56d-276b26d66116",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 50,000 | Num Epochs = 1 | Total steps = 600\n",
            "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 16\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 16 x 1) = 16\n",
            " \"-____-\"     Trainable parameters = 9,605,120 of 7,859,583,312 (0.12% trained)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmmaguero\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251123_110655-901f8nxn</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mmaguero/huggingface/runs/901f8nxn' target=\"_blank\">dutiful-armadillo-58</a></strong> to <a href='https://wandb.ai/mmaguero/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mmaguero/huggingface' target=\"_blank\">https://wandb.ai/mmaguero/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mmaguero/huggingface/runs/901f8nxn' target=\"_blank\">https://wandb.ai/mmaguero/huggingface/runs/901f8nxn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Initializing weave.\n",
            "\u001b[36m\u001b[1mweave\u001b[0m: Logged in as Weights & Biases user: mmaguero.\n",
            "\u001b[36m\u001b[1mweave\u001b[0m: View Weave data at https://wandb.ai/mmaguero/huggingface/weave\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='73' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 73/600 24:23 < 3:00:59, 0.05 it/s, Epoch 0.02/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c42295a"
      },
      "source": [
        "def tokenize_and_prepare_for_eval(examples):\n",
        "    # Tokenize the 'text' field which was created by formatting_prompts_func\n",
        "    tokenized_inputs = tokenizer(\n",
        "        text=examples[\"text\"],\n",
        "        max_length=1024, # Use the model's max sequence length (set during model loading)\n",
        "        truncation=True,\n",
        "        padding='max_length', # Pad to max_length to ensure uniform tensor shapes for batched processing\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='np', # Ensure NumPy arrays are returned\n",
        "    )\n",
        "    # Create labels, initially a copy of input_ids. The data collator will then mask the instruction part.\n",
        "    tokenized_inputs[\"labels\"] = tokenized_inputs[\"input_ids\"].copy()\n",
        "    return tokenized_inputs\n",
        "\n",
        "# Apply the tokenization and label creation to dataset_test\n",
        "dataset_test_prepared = dataset_test.map(\n",
        "    tokenize_and_prepare_for_eval,\n",
        "    batched=True,\n",
        "    remove_columns=dataset_test.column_names, # Remove original columns like 'text', 'input', 'instruction', 'output'\n",
        ")\n",
        "\n",
        "print(\"Prepared dataset_test columns:\", dataset_test_prepared.column_names)\n",
        "print(\"First entry of prepared dataset_test:\", dataset_test_prepared[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f68c951"
      },
      "source": [
        "Now that `dataset_test` has been properly tokenized and includes the `input_ids`, `attention_mask`, and `labels` columns, you can evaluate the model using the `trainer`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac13ab2d"
      },
      "source": [
        "# Now evaluate the model with the prepared dataset\n",
        "trainer.evaluate(dataset_test_prepared)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Show final memory and time stats\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(\n",
        "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
        ")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ],
      "metadata": {
        "id": "pCqnaKmlO1U9",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Let's run the model via Unsloth native inference! According to the `Gemma-3` team, the recommended settings for inference are `temperature = 1.0, top_p = 0.95, top_k = 64`"
      ],
      "metadata": {
        "id": "ekOmTR1hSNcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"gemma-3\",\n",
        ")\n",
        "messages = [{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": [{\n",
        "        \"type\" : \"text\",\n",
        "        \"text\" : \"Ehaíve ko secuencia: 1, 1, 2, 3, 5, 8,\", # fibonacci\n",
        "    }]\n",
        "}]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        "    tokenize = True,\n",
        "    return_dict = True,\n",
        ").to(\"cuda\")\n",
        "outputs = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens = 64, # Increase for longer outputs!\n",
        "    # Recommended Gemma-3 settings!\n",
        "    temperature = 1.0, top_p = 0.95, top_k = 64,\n",
        ")\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "id": "kR3gIAX-SM2q",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        " You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"
      ],
      "metadata": {
        "id": "CrSvZObor0lY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": [{\"type\" : \"text\", \"text\" : \"Mba'érepa hovy yvága?\",}]\n",
        "}]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        "    tokenize = True,\n",
        "    return_dict = True,\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "_ = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens = 64, # Increase for longer outputs!\n",
        "    # Recommended Gemma-3 settings!\n",
        "    temperature = 1.0, top_p = 0.95, top_k = 64,\n",
        "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
        ")"
      ],
      "metadata": {
        "id": "e2pEuRb1r2Vg",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ],
      "metadata": {
        "id": "uMuVrWbjAzhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save_pretrained(\"gemma-3n\")  # Local saving\n",
        "#tokenizer.save_pretrained(\"gemma-3n\")\n",
        "model.push_to_hub(\"mmaguero/alpaca-3.5-gn-gemma-3n-E4B-it\") #, token = hf_token) # Online saving\n",
        "tokenizer.push_to_hub(\"mmaguero/alpaca-3.5-gn-gemma-3n-E4B-it\") #, token = hf_token) # Online saving"
      ],
      "metadata": {
        "id": "upcOlWe7A1vc",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
      ],
      "metadata": {
        "id": "AEEcJ4qfC7Lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "    from unsloth import FastModel\n",
        "    model, tokenizer = FastModel.from_pretrained(\n",
        "        model_name = \"mmaguero/alpaca-3.5-gn-gemma-3n-E4B-it\", #\"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length = 2048,\n",
        "        load_in_4bit = True,\n",
        "    )\n",
        "\n",
        "messages = [{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": [{\"type\" : \"text\", \"text\" : \"Mba'épa ha'e pe Gemma-3N?\",}]\n",
        "}]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        "    tokenize = True,\n",
        "    return_dict = True,\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "_ = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens = 128, # Increase for longer outputs!\n",
        "    # Recommended Gemma-3 settings!\n",
        "    temperature = 1.0, top_p = 0.95, top_k = 64,\n",
        "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
        ")"
      ],
      "metadata": {
        "id": "MKX_XKs_BNZR",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly for deployment! We save it in the folder `gemma-3N-finetune`. Set `if False` to `if True` to let it run!"
      ],
      "metadata": {
        "id": "f422JgM9sdVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if False: # Change to True to save finetune!\n",
        "    model.save_pretrained_merged(\"gemma-3N-finetune\", tokenizer)"
      ],
      "metadata": {
        "id": "iHjt_SMYsd3P",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to upload / push to your Hugging Face account, set `if False` to `if True` and add your Hugging Face token and upload location!"
      ],
      "metadata": {
        "id": "z6O48DbNIAr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if True: # Change to True to upload finetune\n",
        "    try:\n",
        "        trainer.push_to_hub(\"mmaguero/alpaca-3.5-gn-gemma-3n-E4B-it\")\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        model.push_to_hub_merged(\n",
        "            \"mmaguero/alpaca-3.5-gn-gemma-3n-E4B-it\", tokenizer,\n",
        "            #token = hf_token\n",
        "        )"
      ],
      "metadata": {
        "id": "ZV-CiKPrIFG0",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now for all models! For now, you can convert easily to `Q8_0, F16 or BF16` precision. `Q4_K_M` for 4bit will come later!"
      ],
      "metadata": {
        "id": "TCv4vXHd61i7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if False: # Change to True to save to GGUF\n",
        "    model.save_pretrained_gguf(\n",
        "        \"gemma-3N-finetune\",\n",
        "        quantization_type = \"Q8_0\", # For now only Q8_0, BF16, F16 supported\n",
        "    )"
      ],
      "metadata": {
        "id": "FqfebeAdT073",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Likewise, if you want to instead push to GGUF to your Hugging Face account, set `if False` to `if True` and add your Hugging Face token and upload location!"
      ],
      "metadata": {
        "id": "Q974YEVPI7JS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if True: # Change to True to upload GGUF\n",
        "    model.push_to_hub_gguf(\n",
        "        \"mmaguero/alpaca-3.5-gn-gemma-3n-E4B-it-gguf\", # This is the repo_id for the GGUF model\n",
        "        tokenizer = tokenizer,\n",
        "        #quantization_type = \"Q8_0\", # Removed as it's not a valid argument for push_to_hub_gguf\n",
        "        #token = hf_token,\n",
        "    )"
      ],
      "metadata": {
        "id": "ZgcJIhJ0I_es",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, use the `gemma-3N-finetune.gguf` file or `gemma-3N-finetune-Q4_K_M.gguf` file in llama.cpp or a UI based system like Jan or Open WebUI. You can install Jan [here](https://github.com/janhq/jan) and Open WebUI [here](https://github.com/open-webui/open-webui)\n",
        "\n",
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Train your own reasoning model - Llama GRPO notebook [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb)\n",
        "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
        "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
        "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
        "\n",
        "## Gemma 3N Notebook collection:\n",
        "1. Gemma 3N **Multimodal inference + conversational finetuning** [Kaggle Notebook](https://www.kaggle.com/code/danielhanchen/gemma-3n-4b-multimodal-finetuning-inference) *⬅️ Your are here*\n",
        "2. Gemma 3N **Vision finetuning** [Kaggle Notebook](https://www.kaggle.com/code/danielhanchen/gemma-3n-4b-vision-finetuning)\n",
        "3. Gemma 3N **Audio finetuning** [Kaggle Notebook](https://www.kaggle.com/code/danielhanchen/gemma-3n-4b-audio-finetuning)\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
        "\n",
        "  Join Discord if you need help + ⭐️ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐️\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "pnz9QOYTMvbH"
      }
    }
  ]
}